{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bccb461-f7a8-460f-a3b3-2ebcdd67d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U \"transformers==4.36.2\" \"datasets==2.16.1\" \"accelerate==0.26.1\" \"bitsandbytes==0.42.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9619da1-c33d-4fda-9113-e77ec93857cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U git+https://github.com/huggingface/trl@a3c5b7178ac4f65569975efadc97db2f3749c65e\n",
    "# !pip install -q -U git+https://github.com/huggingface/peft@4a1559582281fc3c9283892caea8ccef1d6f5a4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff66e03-2a82-4067-bd11-637986e2a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36394dba-12a0-49a6-b6db-fa225662de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ee0233-3f72-41d7-8028-0041fff779e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 03:52:40.641445: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-18 03:52:40.680093: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-18 03:52:40.680121: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-18 03:52:40.681261: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-18 03:52:40.688029: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-18 03:52:42,156] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac441cb3-86f0-41b7-825e-139f57fa2035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b976f8d-8a83-4cdb-9b41-9c558cf52fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"working on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de63545c-8b7b-49f8-b1d1-8bd6de3dea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_eval = []\n",
    "y_eval = []\n",
    "X_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57e0c78d-6624-4b71-a25c-6479d3960a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(text,lab):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{text}] = {lab}\n",
    "            \"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(text):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{text}] = \"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "337b6b6f-b1d4-481f-b2e2-e2bf9df79726",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hineng/train.txt',encoding='UTF-8') as rf:\n",
    "    lines = rf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a078302d-5047-44dc-b28a-5bd7bfb31d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for lin in lines:\n",
    "    da = lin.split('\\t')\n",
    "    lab = da[1].strip()\n",
    "    X_train.append(da[0])\n",
    "    y_train.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "627a3731-4681-4bcf-9e34-f516265626b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000,\n",
       " 'nen vist bolest vztek smutek zmatek osam lost beznad j a nakonec jen klid Asi takhle vypad m j life')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "713b89a3-3783-4d18-867f-83efafed9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hineng/validation.txt',encoding='UTF-8') as rf:\n",
    "    lines = rf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "462117f7-02f4-4bd5-bc5e-33b042f22c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lin in lines:\n",
    "    da = lin.split('\\t')\n",
    "    lab = da[1].strip()\n",
    "    X_eval.append(da[0])\n",
    "    y_eval.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4123e86e-9cf9-4068-8166-b33930a14eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,\n",
       " 'prahladspatel modi mantrimandal may samil honay par badhai narmaday har')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_eval),X_eval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f540793a-9d8a-4d62-a210-b3d2c52e5758",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hineng/test.txt',encoding='UTF-8') as rf:\n",
    "    lines = rf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8af625bb-bf20-4983-b661-d023a0ec44f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "y_test = []\n",
    "for lin in lines:\n",
    "    da = lin.split('\\t')\n",
    "    lab = da[1].strip()\n",
    "    X_test.append(da[0])\n",
    "    y_test.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7535f8-38cf-49d6-9a2f-ff531eb9ab0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc8bebae-3077-4978-9d51-c561a6360789",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bd828d6-a1bc-43ea-a5d1-ef84f461fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    train_data.append(generate_prompt(X_train[i],y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98748421-df41-43df-b40c-d0216838e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33c58d53-d0ba-49cd-b364-e8dfbea2b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097fffc2-d7e7-4bf6-9355-d8a969a043a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8feed73d-a37e-469b-9828-724a261672ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = []\n",
    "for i in range(len(X_eval)):\n",
    "    eval_data.append(generate_prompt(X_eval[i],y_eval[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec9e7334-dd8b-4be4-9d37-a154cc90c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(eval_data, columns=['text'])\n",
    "eval_data = Dataset.from_pandas(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1975a866-54e9-423b-a6de-9f7140730d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 3000\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4745cc87-cbf7-484f-b2a2-4f0578624e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(len(X_test)):\n",
    "    test_data.append(generate_test_prompt(X_test[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf6f7490-6a43-4409-89b8-44a8ed9d0d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_data, columns=['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "939297ce-b0a3-4595-8853-fbb34c175aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "922b9706-d941-41fb-b57a-f12996e83c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels = ['positive', 'neutral', 'negative']\n",
    "    mapping = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "    \n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f181c797-edaf-44a1-9281-1df2ac9eca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb432033-af2f-43a3-9447-94803bf27155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9415199de3284068b5859f8933c6ef2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"sarvamai/OpenHathi-7B-Hi-v0.1-Base\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device,\n",
    "    torch_dtype=compute_dtype,\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                          trust_remote_code=True,\n",
    "                                         )\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfa7da0f-0abd-468e-a483-d247115cedca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fe3a90989f4e8da07781235c4621b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcdf699876c04f93a10954a3c50f57c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "output_dir=\"trained_weigths\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=16, \n",
    "        lora_dropout=0.05,\n",
    "        r=64,\n",
    "        bias=\"none\",\n",
    "        target_modules =[\"q_proj\", \"v_proj\", \"k_proj\", \"down_proj\", \"gate_proj\", \"up_proj\"],\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,                    # directory to save and repository id\n",
    "    num_train_epochs=4,                       # number of training epochs\n",
    "    per_device_train_batch_size=16,            # batch size per device during training\n",
    "    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=25,                         # log every 10 steps\n",
    "    learning_rate=5e-4,                       # learning rate, based on QLoRA paper\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
    "    report_to=\"tensorboard\",                  # report metrics to tensorboard\n",
    "    evaluation_strategy=\"epoch\"               # save checkpoint every epoch\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=1024,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,\n",
    "        \"append_concat_token\": False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0586b48-bae7-4f6f-b3be-18297617ebe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='436' max='436' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [436/436 1:17:35, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.699700</td>\n",
       "      <td>1.754391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.565400</td>\n",
       "      <td>1.630891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.490100</td>\n",
       "      <td>1.605512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.369800</td>\n",
       "      <td>1.613118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=436, training_loss=1.5894890531487422, metrics={'train_runtime': 4666.1281, 'train_samples_per_second': 12.001, 'train_steps_per_second': 0.093, 'total_flos': 2.412397672487977e+17, 'train_loss': 1.5894890531487422, 'epoch': 3.99})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b060f02-b6fe-4f87-942a-8f13e76ea414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trained_weigths/tokenizer_config.json',\n",
       " 'trained_weigths/special_tokens_map.json',\n",
       " 'trained_weigths/tokenizer.model',\n",
       " 'trained_weigths/added_tokens.json',\n",
       " 'trained_weigths/tokenizer.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "550197fa-57d5-4440-8513-61c1a48d9bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6f651fa3bc460d8b7fa7e6e5d5c618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./merged_model/tokenizer_config.json',\n",
       " './merged_model/special_tokens_map.json',\n",
       " './merged_model/tokenizer.model',\n",
       " './merged_model/added_tokens.json',\n",
       " './merged_model/tokenizer.json')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "finetuned_model = \"./trained_weigths/\"\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sarvamai/OpenHathi-7B-Hi-v0.1-Base\")\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "     finetuned_model,\n",
    "     torch_dtype=compute_dtype,\n",
    "     return_dict=False,\n",
    "     low_cpu_mem_usage=True,\n",
    "     device_map=device,\n",
    ")\n",
    "\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"./merged_model\",safe_serialization=True, max_shard_size=\"2GB\")\n",
    "tokenizer.save_pretrained(\"./merged_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1458244b-607f-4686-9a92-4e056cc1f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = predict(test_df, merged_model, tokenizer)\n",
    "# evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a6244c-a8ce-4cb3-9f29-fcf5c8068424",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15eb83-c206-4822-8b20-d8553c7786d7",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_pred = []\n",
    "# for i in tqdm(range(len(test_data))):\n",
    "#     prompt = test_data[i]\n",
    "#     pipe = pipeline(task=\"text-generation\", \n",
    "#                         model=merged_model, \n",
    "#                         tokenizer=tokenizer, \n",
    "#                         max_new_tokens = 1, \n",
    "#                         temperature = 0.0,\n",
    "#                        )\n",
    "#     result = pipe(prompt)\n",
    "#     answer = result[0]['generated_text'].split(\"=\")[-1]\n",
    "#     if \"positive\" in answer:\n",
    "#         y_pred.append(\"positive\")\n",
    "#     elif \"negative\" in answer:\n",
    "#          y_pred.append(\"negative\")\n",
    "#     else:\n",
    "#         y_pred.append(\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea15843-3877-4780-ba18-780e10f89ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9773d3c-0e7d-4e60-813f-49bb4c59be8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe5d1a-1b63-46b8-912e-b5feca1f62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cad94f-1b1c-430c-868b-5f6e24fd31a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████▌          | 2194/3000 [01:09<00:25, 31.74it/s]"
     ]
    }
   ],
   "source": [
    " y_pred = []\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    prompt = test_data[i]\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    max_new_tokens = 1\n",
    "    temperature = 0.1\n",
    "    output = merged_model.generate(input_ids=inputs.input_ids, \n",
    "                               max_length=len(inputs.input_ids[0]) + max_new_tokens, \n",
    "                               temperature=temperature, \n",
    "                               pad_token_id=tokenizer.eos_token_id,\n",
    "                               eos_token_id=tokenizer.pad_token_id)\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    answer = generated_text.split(\"=\")[-1]\n",
    "    if \"positive\" in answer:\n",
    "       y_pred.append(\"positive\")\n",
    "    elif \"negative\" in answer:\n",
    "       y_pred.append(\"negative\")\n",
    "    else:\n",
    "       y_pred.append(\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0e64888b-f6e9-4b78-aa59-06d4914aefdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "weighted_f1 = f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e057e21c-b346-42b6-a047-d02abfc0e92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7327778844651021"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdabdfe2-ea0b-4cd4-8165-69c18721552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"sa_spa_eng\", \"w\") as writer:\n",
    "#         writer.write('\\n'.join(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7f252-78fc-4d3e-a16e-b6fe4787cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83560c4c-a4f9-4f9f-a7d5-ffba3df4a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca47823-5896-4731-a44b-a55f26a4acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d5117-6a58-47f2-9d82-6575e8246348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
