{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9619da1-c33d-4fda-9113-e77ec93857cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U git+https://github.com/huggingface/trl@a3c5b7178ac4f65569975efadc97db2f3749c65e\n",
    "# !pip install -q -U git+https://github.com/huggingface/peft@4a1559582281fc3c9283892caea8ccef1d6f5a4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff66e03-2a82-4067-bd11-637986e2a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36394dba-12a0-49a6-b6db-fa225662de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ee0233-3f72-41d7-8028-0041fff779e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b976f8d-8a83-4cdb-9b41-9c558cf52fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"working on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de63545c-8b7b-49f8-b1d1-8bd6de3dea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_eval = []\n",
    "y_eval = []\n",
    "X_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57e0c78d-6624-4b71-a25c-6479d3960a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(text,lab):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{text}] = {lab}\n",
    "            \"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(text):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{text}] = \"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "337b6b6f-b1d4-481f-b2e2-e2bf9df79726",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hineng/train.txt',encoding='UTF-8') as rf:\n",
    "    lines = rf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a078302d-5047-44dc-b28a-5bd7bfb31d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for lin in lines:\n",
    "    da = lin.split('\\t')\n",
    "    lab = da[1].strip()\n",
    "    X_train.append(da[0])\n",
    "    y_train.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "627a3731-4681-4bcf-9e34-f516265626b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000,\n",
       " 'nen vist bolest vztek smutek zmatek osam lost beznad j a nakonec jen klid Asi takhle vypad m j life')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "713b89a3-3783-4d18-867f-83efafed9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hineng/validation.txt',encoding='UTF-8') as rf:\n",
    "    lines = rf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462117f7-02f4-4bd5-bc5e-33b042f22c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lin in lines:\n",
    "    da = lin.split('\\t')\n",
    "    lab = da[1].strip()\n",
    "    X_eval.append(da[0])\n",
    "    y_eval.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4123e86e-9cf9-4068-8166-b33930a14eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,\n",
       " 'prahladspatel modi mantrimandal may samil honay par badhai narmaday har')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_eval),X_eval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f540793a-9d8a-4d62-a210-b3d2c52e5758",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hineng/test.txt',encoding='UTF-8') as rf:\n",
    "    lines = rf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8af625bb-bf20-4983-b661-d023a0ec44f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "y_test = []\n",
    "for lin in lines:\n",
    "    da = lin.split('\\t')\n",
    "    lab = da[1].strip()\n",
    "    X_test.append(da[0])\n",
    "    y_test.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7535f8-38cf-49d6-9a2f-ff531eb9ab0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc8bebae-3077-4978-9d51-c561a6360789",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bd828d6-a1bc-43ea-a5d1-ef84f461fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    train_data.append(generate_prompt(X_train[i],y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98748421-df41-43df-b40c-d0216838e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33c58d53-d0ba-49cd-b364-e8dfbea2b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097fffc2-d7e7-4bf6-9355-d8a969a043a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8feed73d-a37e-469b-9828-724a261672ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m eval_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mX_eval\u001b[49m)):\n\u001b[1;32m      3\u001b[0m     eval_data\u001b[38;5;241m.\u001b[39mappend(generate_prompt(X_eval[i],y_eval[i]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_eval' is not defined"
     ]
    }
   ],
   "source": [
    "eval_data = []\n",
    "for i in range(len(X_eval)):\n",
    "    eval_data.append(generate_prompt(X_eval[i],y_eval[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec9e7334-dd8b-4be4-9d37-a154cc90c7fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43meval_data\u001b[49m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m eval_data \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_pandas(eval_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_data' is not defined"
     ]
    }
   ],
   "source": [
    "eval_df = pd.DataFrame(eval_data, columns=['text'])\n",
    "eval_data = Dataset.from_pandas(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1975a866-54e9-423b-a6de-9f7140730d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 3000\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4745cc87-cbf7-484f-b2a2-4f0578624e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(len(X_test)):\n",
    "    test_data.append(generate_test_prompt(X_test[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf6f7490-6a43-4409-89b8-44a8ed9d0d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_data, columns=['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "939297ce-b0a3-4595-8853-fbb34c175aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "922b9706-d941-41fb-b57a-f12996e83c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels = ['positive', 'neutral', 'negative']\n",
    "    mapping = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "    \n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb432033-af2f-43a3-9447-94803bf27155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81228f57150846f38e44948e8e98e5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device,\n",
    "    torch_dtype=compute_dtype,\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                          trust_remote_code=True,\n",
    "                                         )\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfa7da0f-0abd-468e-a483-d247115cedca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c55e81348042b0b433af99bf28ee6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d75de3354464129adad67cb57e83afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir=\"trained_weigths\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=16, \n",
    "        lora_dropout=0.1,\n",
    "        r=64,\n",
    "        bias=\"none\",\n",
    "        target_modules=\"all-linear\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,                    # directory to save and repository id\n",
    "    num_train_epochs=3,                       # number of training epochs\n",
    "    per_device_train_batch_size=16,            # batch size per device during training\n",
    "    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=25,                         # log every 10 steps\n",
    "    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
    "    report_to=\"tensorboard\",                  # report metrics to tensorboard\n",
    "    evaluation_strategy=\"epoch\"               # save checkpoint every epoch\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=1024,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,\n",
    "        \"append_concat_token\": False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0586b48-bae7-4f6f-b3be-18297617ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='327' max='327' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [327/327 46:11, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.651800</td>\n",
       "      <td>1.680410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.562800</td>\n",
       "      <td>1.611364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.549700</td>\n",
       "      <td>1.602434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=327, training_loss=1.648341805927615, metrics={'train_runtime': 2781.699, 'train_samples_per_second': 15.099, 'train_steps_per_second': 0.118, 'total_flos': 9.368580022389965e+16, 'train_loss': 1.648341805927615, 'epoch': 2.99})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b060f02-b6fe-4f87-942a-8f13e76ea414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trained_weigths/tokenizer_config.json',\n",
       " 'trained_weigths/special_tokens_map.json',\n",
       " 'trained_weigths/tokenizer.model',\n",
       " 'trained_weigths/added_tokens.json',\n",
       " 'trained_weigths/tokenizer.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e39e82-c1a3-4d21-a4d9-c27054271e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1242bc-3200-4997-803e-c1e5aabd2192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550197fa-57d5-4440-8513-61c1a48d9bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98d52f0325c4e61bbcfecb6805ad293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./merged_model/tokenizer_config.json',\n",
       " './merged_model/special_tokens_map.json',\n",
       " './merged_model/tokenizer.model',\n",
       " './merged_model/added_tokens.json',\n",
       " './merged_model/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "finetuned_model = \"./trained_weigths/\"\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "     finetuned_model,\n",
    "     torch_dtype=compute_dtype,\n",
    "     return_dict=False,\n",
    "     low_cpu_mem_usage=True,\n",
    "     device_map=device,\n",
    ")\n",
    "\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"./merged_model\",safe_serialization=True, max_shard_size=\"2GB\")\n",
    "tokenizer.save_pretrained(\"./merged_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1458244b-607f-4686-9a92-4e056cc1f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = predict(test_df, merged_model, tokenizer)\n",
    "# evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a6244c-a8ce-4cb3-9f29-fcf5c8068424",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf15eb83-c206-4822-8b20-d8553c7786d7",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_pred = []\n",
    "# for i in tqdm(range(len(test_data))):\n",
    "#     prompt = test_data[i]\n",
    "#     pipe = pipeline(task=\"text-generation\", \n",
    "#                         model=merged_model, \n",
    "#                         tokenizer=tokenizer, \n",
    "#                         max_new_tokens = 1, \n",
    "#                         temperature = 0.0,\n",
    "#                        )\n",
    "#     result = pipe(prompt)\n",
    "#     answer = result[0]['generated_text'].split(\"=\")[-1]\n",
    "#     if \"positive\" in answer:\n",
    "#         y_pred.append(\"positive\")\n",
    "#     elif \"negative\" in answer:\n",
    "#          y_pred.append(\"negative\")\n",
    "#     else:\n",
    "#         y_pred.append(\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea15843-3877-4780-ba18-780e10f89ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9773d3c-0e7d-4e60-813f-49bb4c59be8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cfe5d1a-1b63-46b8-912e-b5feca1f62d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0cad94f-1b1c-430c-868b-5f6e24fd31a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3000/3000 [01:21<00:00, 36.87it/s]\n"
     ]
    }
   ],
   "source": [
    " y_pred = []\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    prompt = test_data[i]\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    max_new_tokens = 1\n",
    "    temperature = 0.0\n",
    "    output = merged_model.generate(input_ids=inputs.input_ids, \n",
    "                               max_length=len(inputs.input_ids[0]) + max_new_tokens, \n",
    "                               temperature=temperature, \n",
    "                               pad_token_id=tokenizer.eos_token_id,\n",
    "                               eos_token_id=tokenizer.pad_token_id)\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    answer = generated_text.split(\"=\")[-1]\n",
    "    if \"positive\" in answer:\n",
    "       y_pred.append(\"positive\")\n",
    "    elif \"negative\" in answer:\n",
    "       y_pred.append(\"negative\")\n",
    "    else:\n",
    "       y_pred.append(\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e64888b-f6e9-4b78-aa59-06d4914aefdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "weighted_f1 = f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e057e21c-b346-42b6-a047-d02abfc0e92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7173021120191883"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdabdfe2-ea0b-4cd4-8165-69c18721552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sa_spa_eng\", \"w\") as writer:\n",
    "        writer.write('\\n'.join(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7f252-78fc-4d3e-a16e-b6fe4787cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83560c4c-a4f9-4f9f-a7d5-ffba3df4a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca47823-5896-4731-a44b-a55f26a4acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d5117-6a58-47f2-9d82-6575e8246348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
