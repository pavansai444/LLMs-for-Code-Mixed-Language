{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bccb461-f7a8-460f-a3b3-2ebcdd67d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U \"transformers==4.36.2\" \"datasets==2.16.1\" \"accelerate==0.26.1\" \"bitsandbytes==0.42.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9619da1-c33d-4fda-9113-e77ec93857cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U git+https://github.com/huggingface/trl@a3c5b7178ac4f65569975efadc97db2f3749c65e\n",
    "# !pip install -q -U git+https://github.com/huggingface/peft@4a1559582281fc3c9283892caea8ccef1d6f5a4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff66e03-2a82-4067-bd11-637986e2a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36394dba-12a0-49a6-b6db-fa225662de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ee0233-3f72-41d7-8028-0041fff779e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 01:43:40.780430: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-23 01:43:40.816587: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-23 01:43:40.816614: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-23 01:43:40.817512: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-23 01:43:40.823446: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 01:43:42,197] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f83bb29-5f7e-47be-b2a0-063fb4bb6711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"working on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4517cfe6-d1d7-416e-ab4e-d7f2c9a7b2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2448099346e84ba9874956796e2bdddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "# model_name = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "# model_name = \"nousresearch/llama-2-7b-hf\"\n",
    "# model_name='DevilGod870/Llama-2-7b-chat-Hinglish'\n",
    "# peft_model_id = \"nateraw/llama-2-7b-english-to-hinglish\"\n",
    "model_name='sarvamai/OpenHathi-7B-Hi-v0.1-Base'\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device,\n",
    "    torch_dtype=compute_dtype,\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                          trust_remote_code=True,\n",
    "                                         )\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac441cb3-86f0-41b7-825e-139f57fa2035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 259\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "def format_dolly(sample):\n",
    "    context = f\"\\n[question]  {sample['instruction']} [/question]\"\n",
    "    instruction = f\"<s> [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: {sample['context']} [/context]\" if len(sample[\"context\"]) > 0 else None\n",
    "    response = f\"[/INST] [answer] {sample['response']} [/answer]\"\n",
    "    # join all the parts together\n",
    "    prompt = \"\".join([i for i in [instruction, context, response] if i is not None])\n",
    "    return prompt\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{format_dolly(sample)}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "# apply prompt template per sample\n",
    "dataset = load_dataset(\"Vishwanath0912/qa_en_hi\", split=\"train\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset_shuffled = dataset.shuffle(seed=42)\n",
    "\n",
    "# Select the first 50 rows from the shuffled dataset, comment if you want 15k\n",
    "dataset = dataset_shuffled\n",
    "\n",
    "train_qa = dataset.map(template_dataset, remove_columns=list(dataset.features))\n",
    "train_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a5a250-ed31-467b-881c-f1d2a90ffc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1579712ab6d14b67b593a7fba74cd692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780c7fe7728d497ba328c0016435eb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['text'],\n",
       "     num_rows: 10000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text'],\n",
       "     num_rows: 10000\n",
       " }))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "# def format_en(sample):\n",
    "#     context = f\"\"\n",
    "#     instruction = f\"<s> [INST] <<SYS>> Translate the following sentence from English to Hindi English Code Mixed Version (Hinglish). <</SYS>> \\n[sentence]: {sample['en']} [/sentence]\" if len(sample[\"en\"]) > 0 else None\n",
    "#     response = f\" [/INST] [answer] {sample['hi_en']} [/answer]\"\n",
    "#     # join all the parts together\n",
    "#     prompt = \"\".join([i for i in [instruction, context, response] if i is not None])\n",
    "#     return prompt\n",
    "\n",
    "# # template dataset to add prompt to each sample\n",
    "# def template_en(sample):\n",
    "#     sample[\"text\"] = f\"{format_en(sample)}{tokenizer.eos_token}\"\n",
    "#     return sample\n",
    "    \n",
    "# def format_en_hi(sample):\n",
    "#     context = f\"\"\n",
    "#     instruction = f\"<s> [INST] <<SYS>> Translate the following sentence from Hindi English Code Mixed Version (Hinglish) to English . <</SYS>> \\n[sentence]: {sample['hi_en']} [/sentence]\" if len(sample[\"hi_en\"]) > 0 else None\n",
    "#     response = f\" [/INST] [answer] {sample['en']} [/answer]\"\n",
    "#     # join all the parts together\n",
    "#     prompt = \"\".join([i for i in [instruction, context, response] if i is not None])\n",
    "#     return prompt\n",
    "\n",
    "# # template dataset to add prompt to each sample\n",
    "# def template_en_hi(sample):\n",
    "#     sample[\"text\"] = f\"{format_en_hi(sample)}{tokenizer.eos_token}\"\n",
    "#     return sample\n",
    "# # apply prompt template per sample\n",
    "# dataset = load_dataset(\"rvv-karma/English-Hinglish-TOP\", split=\"train\")\n",
    "# dataset =  dataset.shuffle(seed=42)\n",
    "# train_en = Dataset.from_pandas(pd.DataFrame(dataset[0:10000]))\n",
    "# train_en = train_en.map(template_en,remove_columns=list(dataset.features))\n",
    "# train_en_hi = Dataset.from_pandas(pd.DataFrame(dataset[15000:25000]))\n",
    "# train_en_hi = train_en_hi.map(template_en_hi,remove_columns=list(dataset.features))\n",
    "# train_en,train_en_hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5a310818-0de5-462c-82a4-805eb2064282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647300cc208b4f7a8deac2954f517fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e287d5d3191748cc9043c2aec7fbc2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.19G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b95a909a60144b1aae44c14c1cde858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.55M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd6e6502e58419b8274f6ebf701f706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read file '/root/.cache/huggingface/datasets/downloads/6bd4c00e7893146c7e7c50fee85d282fef84aeb3184153315d5747257426c9f9' with error <class 'pyarrow.lib.ArrowInvalid'>: Failed to convert JSON to double, couldn't parse:आपके कठिन परिश्रम ने मुझे प्रेरित किया है।\n"
     ]
    },
    {
     "ename": "DatasetGenerationError",
     "evalue": "An error occurred while generating the dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/packaged_modules/json/json.py:144\u001b[0m, in \u001b[0;36mJson._generate_tables\u001b[0;34m(self, files)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    142\u001b[0m         file, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mencoding_errors\n\u001b[1;32m    143\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 144\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 2 column 1 (char 622607)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py:1973\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[1;32m   1972\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 1973\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1974\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/packaged_modules/json/json.py:147\u001b[0m, in \u001b[0;36mJson._generate_tables\u001b[0;34m(self, files)\u001b[0m\n\u001b[1;32m    146\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to read file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with error \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# If possible, parse the file as a list of json objects/strings and exit the loop\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/packaged_modules/json/json.py:121\u001b[0m, in \u001b[0;36mJson._generate_tables\u001b[0;34m(self, files)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[43mpaj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpaj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReadOptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyarrow/_json.pyx:308\u001b[0m, in \u001b[0;36mpyarrow._json.read_json\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Failed to convert JSON to double, couldn't parse:आपके कठिन परिश्रम ने मुझे प्रेरित किया है।",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatasetGenerationError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# apply prompt template per sample\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSolshine/Hindi_English_QandA_Synth_Data_For_Hinglish_Project\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py:2582\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2579\u001b[0m try_from_hf_gcs \u001b[38;5;241m=\u001b[39m path \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   2581\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 2582\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_from_hf_gcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtry_from_hf_gcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2589\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2591\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2592\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2593\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   2594\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py:1005\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1004\u001b[0m         prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py:1100\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m split_dict\u001b[38;5;241m.\u001b[39madd(split_generator\u001b[38;5;241m.\u001b[39msplit_info)\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[0;32m-> 1100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find data file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_download_instructions \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m   1107\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py:1860\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split\u001b[0;34m(self, split_generator, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[1;32m   1858\u001b[0m job_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[0;32m-> 1860\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_prepare_split_args\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py:2016\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, DatasetGenerationError):\n\u001b[1;32m   2015\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 2016\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while generating the dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m job_id, \u001b[38;5;28;01mTrue\u001b[39;00m, (total_num_examples, total_num_bytes, writer\u001b[38;5;241m.\u001b[39m_features, num_shards, shard_lengths)\n",
      "\u001b[0;31mDatasetGenerationError\u001b[0m: An error occurred while generating the dataset"
     ]
    }
   ],
   "source": [
    "# apply prompt template per sample\n",
    "dataset = load_dataset(\"Solshine/Hindi_English_QandA_Synth_Data_For_Hinglish_Project\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3932ae5-b582-4e54-aba7-9633f336df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6887b183-dd41-4c96-8394-788f887b09b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "def format_dolly(sample):\n",
    "    context = f\"\\n[question]  {sample['instruction']} [/question]\"\n",
    "    instruction = f\"<s> [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: {sample['context']} [/context]\" if len(sample[\"context\"]) > 0 else None\n",
    "    response = f\"[/INST] [answer] {sample['response']} [/answer]\"\n",
    "    # join all the parts together\n",
    "    prompt = \"\".join([i for i in [instruction, context, response] if i is not None])\n",
    "    return prompt\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{format_dolly(sample)}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset_shuffled = dataset.shuffle(seed=42)\n",
    "\n",
    "# Select the first 50 rows from the shuffled dataset, comment if you want 15k\n",
    "dataset = dataset_shuffled\n",
    "\n",
    "train_qa = dataset.map(template_dataset, remove_columns=list(dataset.features))\n",
    "train_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b976f8d-8a83-4cdb-9b41-9c558cf52fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"working on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de63545c-8b7b-49f8-b1d1-8bd6de3dea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_eval = []\n",
    "y_eval = []\n",
    "X_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57e0c78d-6624-4b71-a25c-6479d3960a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(text,lab):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{text}] = {lab}\n",
    "            \"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(text):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{text}] = \"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "337b6b6f-b1d4-481f-b2e2-e2bf9df79726",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hineng/train.txt',encoding='UTF-8') as rf:\n",
    "    lines = rf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a078302d-5047-44dc-b28a-5bd7bfb31d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lin in lines:\n",
    "    da = lin.split('\\t')\n",
    "    lab = da[1].strip()\n",
    "    X_train.append(da[0])\n",
    "    y_train.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "627a3731-4681-4bcf-9e34-f516265626b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000,\n",
       " 'nen vist bolest vztek smutek zmatek osam lost beznad j a nakonec jen klid Asi takhle vypad m j life')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "713b89a3-3783-4d18-867f-83efafed9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hineng/validation.txt',encoding='UTF-8') as rf:\n",
    "    lines = rf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "462117f7-02f4-4bd5-bc5e-33b042f22c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lin in lines:\n",
    "    da = lin.split('\\t')\n",
    "    lab = da[1].strip()\n",
    "    X_eval.append(da[0])\n",
    "    y_eval.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4123e86e-9cf9-4068-8166-b33930a14eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,\n",
       " 'prahladspatel modi mantrimandal may samil honay par badhai narmaday har')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_eval),X_eval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f540793a-9d8a-4d62-a210-b3d2c52e5758",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hineng/test.txt',encoding='UTF-8') as rf:\n",
    "    lines = rf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8af625bb-bf20-4983-b661-d023a0ec44f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "y_test = []\n",
    "for lin in lines:\n",
    "    da = lin.split('\\t')\n",
    "    lab = da[1].strip()\n",
    "    X_test.append(da[0])\n",
    "    y_test.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe947cc2-dbd6-4dd9-8d27-40616eec17b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6fd84e-6eb6-4183-ad5e-6d82bf4508e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7535f8-38cf-49d6-9a2f-ff531eb9ab0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc8bebae-3077-4978-9d51-c561a6360789",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bd828d6-a1bc-43ea-a5d1-ef84f461fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    train_data.append(generate_prompt(X_train[i],y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc2d16ee-420f-4b67-addd-e66a0ba90a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in train_qa['text']:\n",
    "    train_data.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3943fbb9-98c7-495d-a185-a64dae128bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in train_en['text']:\n",
    "    train_data.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3815f42-a8ae-41db-b19e-4ed2eb704cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in train_en_hi['text']:\n",
    "    train_data.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98748421-df41-43df-b40c-d0216838e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33c58d53-d0ba-49cd-b364-e8dfbea2b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "097fffc2-d7e7-4bf6-9355-d8a969a043a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Assuming train_data is your Dataset object\n",
    "train_data = train_data.shuffle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0598fe4b-46f9-411b-a410-0212735a944f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34259"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8feed73d-a37e-469b-9828-724a261672ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = []\n",
    "for i in range(len(X_eval)):\n",
    "    eval_data.append(generate_prompt(X_eval[i],y_eval[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec9e7334-dd8b-4be4-9d37-a154cc90c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(eval_data, columns=['text'])\n",
    "eval_data = Dataset.from_pandas(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1975a866-54e9-423b-a6de-9f7140730d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 3000\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4745cc87-cbf7-484f-b2a2-4f0578624e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(len(X_test)):\n",
    "    test_data.append(generate_test_prompt(X_test[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf6f7490-6a43-4409-89b8-44a8ed9d0d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_data, columns=['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "939297ce-b0a3-4595-8853-fbb34c175aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "922b9706-d941-41fb-b57a-f12996e83c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels = ['positive', 'neutral', 'negative']\n",
    "    mapping = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "    \n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f181c797-edaf-44a1-9281-1df2ac9eca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfa7da0f-0abd-468e-a483-d247115cedca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad0f8349a2a407897d650d02daab95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34259 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "output_dir=\"trained_weigths\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=32, \n",
    "        lora_dropout=0.05,\n",
    "        r=16,\n",
    "        bias=\"none\",\n",
    "        target_modules =[\"q_proj\", \"v_proj\", \"k_proj\", \"down_proj\", \"gate_proj\", \"up_proj\"],\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,                    # directory to save and repository id\n",
    "    num_train_epochs=4,                       # number of training epochs\n",
    "    per_device_train_batch_size=24,            # batch size per device during training\n",
    "    gradient_accumulation_steps=1,            # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=25,                         # log every 10 steps\n",
    "    learning_rate=5e-4,                       # learning rate, based on QLoRA paper\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
    "    report_to=\"tensorboard\",                  # report metrics to tensorboard\n",
    "    # evaluation_strategy=\"epoch\"               # save checkpoint every epoch\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_data,\n",
    "    # eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=1024,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,\n",
    "        \"append_concat_token\": False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0586b48-bae7-4f6f-b3be-18297617ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5712' max='5712' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5712/5712 2:20:31, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.480500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.748500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.524400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.570700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.503000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.558400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.489900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.580500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.498900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.516500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.465400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.505100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.461200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.554100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.474300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.446800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.520900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.458400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.520900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.465200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>1.502900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>1.398500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.433300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>1.466100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.438900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>1.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.440100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>1.462500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.437700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>1.492700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.451600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>1.452900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.444800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>1.513700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.454000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>1.506400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.438300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>1.528500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.468900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>1.440700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.453000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>1.485500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.446500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>1.429300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.426100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>1.398900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.429300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>1.441400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.461700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>1.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.424700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>1.061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>1.234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>0.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.256600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>0.440400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>1.257100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>0.411500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>0.459300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>1.217700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>0.420100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.269600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>0.418500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>1.249300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>0.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>0.439600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>1.268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>0.452600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.188800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>0.419700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>1.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>0.424300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.221400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>0.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>1.218500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>0.436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.231300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>0.442000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>1.261700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175</td>\n",
       "      <td>0.469500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.252600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2225</td>\n",
       "      <td>0.419300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>1.231400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>0.455900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2325</td>\n",
       "      <td>0.430900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>1.243900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2375</td>\n",
       "      <td>0.438900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2425</td>\n",
       "      <td>0.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>1.209800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>0.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.168400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2525</td>\n",
       "      <td>0.415500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>1.183700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2575</td>\n",
       "      <td>0.435800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.240400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2625</td>\n",
       "      <td>0.431400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>1.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>0.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.210500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2725</td>\n",
       "      <td>0.428500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>1.227700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2775</td>\n",
       "      <td>0.431200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2825</td>\n",
       "      <td>0.453500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.892800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2875</td>\n",
       "      <td>0.931900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.365600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2925</td>\n",
       "      <td>0.936700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.363400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2975</td>\n",
       "      <td>0.967300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.374200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3025</td>\n",
       "      <td>0.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.358600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3075</td>\n",
       "      <td>0.986600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.391100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3125</td>\n",
       "      <td>0.920900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.364400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3175</td>\n",
       "      <td>0.938400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.356600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3225</td>\n",
       "      <td>0.973800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.395400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3275</td>\n",
       "      <td>0.968400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.388100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3325</td>\n",
       "      <td>0.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.365100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3375</td>\n",
       "      <td>0.924600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.390400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3425</td>\n",
       "      <td>0.941400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.359900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3475</td>\n",
       "      <td>0.917600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.353400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3525</td>\n",
       "      <td>0.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.364200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3575</td>\n",
       "      <td>0.908300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.351800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3625</td>\n",
       "      <td>0.927200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.347600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3675</td>\n",
       "      <td>0.879200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.365100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3725</td>\n",
       "      <td>0.935300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.374700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3775</td>\n",
       "      <td>0.932900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.402700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3825</td>\n",
       "      <td>0.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.393300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3875</td>\n",
       "      <td>0.882100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.365700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3925</td>\n",
       "      <td>0.919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.374200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3975</td>\n",
       "      <td>0.891300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.369200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4025</td>\n",
       "      <td>0.895600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.362700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4075</td>\n",
       "      <td>0.925700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.360900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4125</td>\n",
       "      <td>0.938900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.359900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4175</td>\n",
       "      <td>0.925800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.366500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4225</td>\n",
       "      <td>0.886800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4275</td>\n",
       "      <td>0.708600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.679500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4325</td>\n",
       "      <td>0.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4375</td>\n",
       "      <td>0.307600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.647700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4425</td>\n",
       "      <td>0.282400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.696700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4475</td>\n",
       "      <td>0.323700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.690500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4525</td>\n",
       "      <td>0.309400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>0.664800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4575</td>\n",
       "      <td>0.287300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.659200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4625</td>\n",
       "      <td>0.302000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>0.618800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4675</td>\n",
       "      <td>0.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.651500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4725</td>\n",
       "      <td>0.313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.668900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4775</td>\n",
       "      <td>0.302800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.617600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4825</td>\n",
       "      <td>0.270600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>0.636700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4875</td>\n",
       "      <td>0.288800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.666400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4925</td>\n",
       "      <td>0.284900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>0.646700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4975</td>\n",
       "      <td>0.305800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.654300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5025</td>\n",
       "      <td>0.284600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>0.634800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5075</td>\n",
       "      <td>0.288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.624100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5125</td>\n",
       "      <td>0.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>0.642100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5175</td>\n",
       "      <td>0.292200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5225</td>\n",
       "      <td>0.290400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>0.651800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5275</td>\n",
       "      <td>0.289700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.627600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5325</td>\n",
       "      <td>0.303800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>0.630800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5375</td>\n",
       "      <td>0.286300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.645900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5425</td>\n",
       "      <td>0.281600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>0.643600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5475</td>\n",
       "      <td>0.295400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.642200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5525</td>\n",
       "      <td>0.287200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>0.624800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5575</td>\n",
       "      <td>0.278400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.648000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5625</td>\n",
       "      <td>0.288100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>0.612800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5675</td>\n",
       "      <td>0.273600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.486600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5712, training_loss=0.7423979064830545, metrics={'train_runtime': 8443.7774, 'train_samples_per_second': 16.229, 'train_steps_per_second': 0.676, 'total_flos': 5.838437179312374e+17, 'train_loss': 0.7423979064830545, 'epoch': 4.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b060f02-b6fe-4f87-942a-8f13e76ea414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trained_weigths/tokenizer_config.json',\n",
       " 'trained_weigths/special_tokens_map.json',\n",
       " 'trained_weigths/tokenizer.model',\n",
       " 'trained_weigths/added_tokens.json',\n",
       " 'trained_weigths/tokenizer.json')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ffd5d7-d9b5-46eb-af66-66f14c94e13a",
   "metadata": {},
   "source": [
    "# without finetuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecad6109-8193-4da0-9d23-9ec5e1e106c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  y_pred = []\n",
    "# for i in tqdm(range(len(test_data))):\n",
    "#     prompt = test_data[i]\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "#     max_new_tokens = 1\n",
    "#     temperature = 0.1\n",
    "#     output = model.generate(input_ids=inputs.input_ids, \n",
    "#                                max_length=len(inputs.input_ids[0]) + max_new_tokens, \n",
    "#                                temperature=temperature, \n",
    "#                                pad_token_id=tokenizer.eos_token_id,\n",
    "#                                eos_token_id=tokenizer.pad_token_id)\n",
    "#     generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "#     answer = generated_text.split(\"=\")[-1]\n",
    "#     if \"positive\" in answer:\n",
    "#        y_pred.append(\"positive\")\n",
    "#     elif \"negative\" in answer:\n",
    "#        y_pred.append(\"negative\")\n",
    "#     else:\n",
    "#        y_pred.append(\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "550197fa-57d5-4440-8513-61c1a48d9bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b24e6106cb549628e60628ecb172e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./merged_model/tokenizer_config.json',\n",
       " './merged_model/special_tokens_map.json',\n",
       " './merged_model/tokenizer.model',\n",
       " './merged_model/added_tokens.json',\n",
       " './merged_model/tokenizer.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "finetuned_model = \"./trained_weigths/\"\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sarvamai/OpenHathi-7B-Hi-v0.1-Base\")\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "     finetuned_model,\n",
    "     torch_dtype=compute_dtype,\n",
    "     return_dict=False,\n",
    "     low_cpu_mem_usage=True,\n",
    "     device_map=device,\n",
    ")\n",
    "\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"./merged_model\",safe_serialization=True, max_shard_size=\"2GB\")\n",
    "tokenizer.save_pretrained(\"./merged_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1458244b-607f-4686-9a92-4e056cc1f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = predict(test_df, merged_model, tokenizer)\n",
    "# evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09a6244c-a8ce-4cb3-9f29-fcf5c8068424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     Analyze the sentiment of the news headline enc...\n",
       "1     Analyze the sentiment of the news headline enc...\n",
       "2     Analyze the sentiment of the news headline enc...\n",
       "3     Analyze the sentiment of the news headline enc...\n",
       "4     Analyze the sentiment of the news headline enc...\n",
       "...                                                 ...\n",
       "2995  Analyze the sentiment of the news headline enc...\n",
       "2996  Analyze the sentiment of the news headline enc...\n",
       "2997  Analyze the sentiment of the news headline enc...\n",
       "2998  Analyze the sentiment of the news headline enc...\n",
       "2999  Analyze the sentiment of the news headline enc...\n",
       "\n",
       "[3000 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf15eb83-c206-4822-8b20-d8553c7786d7",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_pred = []\n",
    "# for i in tqdm(range(len(test_data))):\n",
    "#     prompt = test_data[i]\n",
    "#     pipe = pipeline(task=\"text-generation\", \n",
    "#                         model=merged_model, \n",
    "#                         tokenizer=tokenizer, \n",
    "#                         max_new_tokens = 1, \n",
    "#                         temperature = 0.0,\n",
    "#                        )\n",
    "#     result = pipe(prompt)\n",
    "#     answer = result[0]['generated_text'].split(\"=\")[-1]\n",
    "#     if \"positive\" in answer:\n",
    "#         y_pred.append(\"positive\")\n",
    "#     elif \"negative\" in answer:\n",
    "#          y_pred.append(\"negative\")\n",
    "#     else:\n",
    "#         y_pred.append(\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea15843-3877-4780-ba18-780e10f89ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9773d3c-0e7d-4e60-813f-49bb4c59be8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cfe5d1a-1b63-46b8-912e-b5feca1f62d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0cad94f-1b1c-430c-868b-5f6e24fd31a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3000/3000 [01:18<00:00, 38.33it/s]\n"
     ]
    }
   ],
   "source": [
    " y_pred = []\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    prompt = test_data[i]\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    max_new_tokens = 1\n",
    "    temperature = 0.0001\n",
    "    output = merged_model.generate(input_ids=inputs.input_ids, \n",
    "                               max_length=len(inputs.input_ids[0]) + max_new_tokens, \n",
    "                               temperature=temperature, \n",
    "                               pad_token_id=tokenizer.eos_token_id,\n",
    "                               eos_token_id=tokenizer.pad_token_id)\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    answer = generated_text.split(\"=\")[-1]\n",
    "    if \"positive\" in answer:\n",
    "       y_pred.append(\"positive\")\n",
    "    elif \"negative\" in answer:\n",
    "       y_pred.append(\"negative\")\n",
    "    else:\n",
    "       y_pred.append(\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e64888b-f6e9-4b78-aa59-06d4914aefdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "weighted_f1 = f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e057e21c-b346-42b6-a047-d02abfc0e92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7368453476677815"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bdabdfe2-ea0b-4cd4-8165-69c18721552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"sa_spa_eng\", \"w\") as writer:\n",
    "#         writer.write('\\n'.join(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16d7f252-78fc-4d3e-a16e-b6fe4787cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83560c4c-a4f9-4f9f-a7d5-ffba3df4a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fca47823-5896-4731-a44b-a55f26a4acfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "890d5117-6a58-47f2-9d82-6575e8246348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c30f5-8f94-44f6-973b-5031e1e294bb",
   "metadata": {},
   "source": [
    "# QA TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2031aee8-d410-409e-a792-bacc98a5837e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 54\n",
       "})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "def format_dolly(sample):\n",
    "    context = f\"\\n[question]  {sample['instruction']} [/question]\"\n",
    "    instruction = f\"<s> [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: {sample['context']} [/context]\" if len(sample[\"context\"]) > 0 else None\n",
    "    response = f\"[/INST]\"\n",
    "    # join all the parts together\n",
    "    prompt = \"\".join([i for i in [instruction, context, response] if i is not None])\n",
    "    return prompt\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{format_dolly(sample)}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "# apply prompt template per sample\n",
    "dataset = load_dataset(\"Vishwanath0912/qa_en_hi\", split=\"validation\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "# dataset_shuffled = dataset.shuffle(seed=42)\n",
    "\n",
    "# Select the first 50 rows from the shuffled dataset, comment if you want 15k\n",
    "# dataset = dataset_shuffled\n",
    "\n",
    "dataset = dataset.map(template_dataset, remove_columns=list(dataset.features))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d5d6e1f-6ec8-4ab5-9133-8f28bb9e99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(strings):\n",
    "    answers = []\n",
    "    for s in strings:\n",
    "        ts = s[s.find('[/INST]'):]\n",
    "        start = ts.find('[answer]')+len('[answer]')\n",
    "        end = ts.find('[/answer]')\n",
    "        if start!=-1 and end!=-1:\n",
    "            answers.append(ts[start:end])\n",
    "        else:\n",
    "            answers.append(ts)\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b085447-17d1-4640-9d1d-2c0b7f183798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/54 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  2%|▊                                           | 1/54 [00:01<01:34,  1.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  4%|█▋                                          | 2/54 [00:03<01:28,  1.70s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  6%|██▍                                         | 3/54 [00:05<01:25,  1.68s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  7%|███▎                                        | 4/54 [00:06<01:22,  1.66s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  9%|████                                        | 5/54 [00:08<01:20,  1.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 11%|████▉                                       | 6/54 [00:09<01:19,  1.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 13%|█████▋                                      | 7/54 [00:11<01:17,  1.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 15%|██████▌                                     | 8/54 [00:13<01:16,  1.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 17%|███████▎                                    | 9/54 [00:14<01:14,  1.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 19%|███████▉                                   | 10/54 [00:16<01:13,  1.66s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 20%|████████▊                                  | 11/54 [00:18<01:13,  1.72s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 22%|█████████▌                                 | 12/54 [00:20<01:13,  1.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 24%|██████████▎                                | 13/54 [00:22<01:13,  1.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 26%|███████████▏                               | 14/54 [00:23<01:10,  1.75s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 28%|███████████▉                               | 15/54 [00:25<01:08,  1.75s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 30%|████████████▋                              | 16/54 [00:27<01:07,  1.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 31%|█████████████▌                             | 17/54 [00:29<01:03,  1.73s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 33%|██████████████▎                            | 18/54 [00:30<01:01,  1.70s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 35%|███████████████▏                           | 19/54 [00:32<00:59,  1.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 37%|███████████████▉                           | 20/54 [00:33<00:56,  1.67s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 39%|████████████████▋                          | 21/54 [00:35<00:54,  1.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 41%|█████████████████▌                         | 22/54 [00:37<00:52,  1.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 43%|██████████████████▎                        | 23/54 [00:38<00:50,  1.64s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 44%|███████████████████                        | 24/54 [00:40<00:49,  1.64s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 46%|███████████████████▉                       | 25/54 [00:42<00:47,  1.64s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 48%|████████████████████▋                      | 26/54 [00:43<00:45,  1.64s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 50%|█████████████████████▌                     | 27/54 [00:45<00:44,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 52%|██████████████████████▎                    | 28/54 [00:46<00:42,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 54%|███████████████████████                    | 29/54 [00:48<00:40,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 56%|███████████████████████▉                   | 30/54 [00:50<00:39,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 57%|████████████████████████▋                  | 31/54 [00:51<00:37,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 59%|█████████████████████████▍                 | 32/54 [00:53<00:35,  1.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 61%|██████████████████████████▎                | 33/54 [00:55<00:34,  1.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 63%|███████████████████████████                | 34/54 [00:56<00:32,  1.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 65%|███████████████████████████▊               | 35/54 [00:58<00:30,  1.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 67%|████████████████████████████▋              | 36/54 [00:59<00:29,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 69%|█████████████████████████████▍             | 37/54 [01:01<00:27,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 70%|██████████████████████████████▎            | 38/54 [01:03<00:26,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 72%|███████████████████████████████            | 39/54 [01:04<00:24,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 74%|███████████████████████████████▊           | 40/54 [01:06<00:22,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 76%|████████████████████████████████▋          | 41/54 [01:08<00:21,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 78%|█████████████████████████████████▍         | 42/54 [01:09<00:19,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 80%|██████████████████████████████████▏        | 43/54 [01:11<00:17,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 81%|███████████████████████████████████        | 44/54 [01:12<00:16,  1.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 83%|███████████████████████████████████▊       | 45/54 [01:14<00:14,  1.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 85%|████████████████████████████████████▋      | 46/54 [01:16<00:12,  1.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 87%|█████████████████████████████████████▍     | 47/54 [01:17<00:11,  1.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 89%|██████████████████████████████████████▏    | 48/54 [01:19<00:09,  1.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 91%|███████████████████████████████████████    | 49/54 [01:21<00:08,  1.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 93%|███████████████████████████████████████▊   | 50/54 [01:22<00:06,  1.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 94%|████████████████████████████████████████▌  | 51/54 [01:24<00:04,  1.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 96%|█████████████████████████████████████████▍ | 52/54 [01:25<00:03,  1.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 98%|██████████████████████████████████████████▏| 53/54 [01:27<00:01,  1.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "100%|███████████████████████████████████████████| 54/54 [01:29<00:00,  1.65s/it]\n"
     ]
    }
   ],
   "source": [
    "y_pred=[]\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    prompt = dataset[i]['text']\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    max_new_tokens = 64\n",
    "    temperature = 0.1\n",
    "    output = merged_model.generate(input_ids=inputs.input_ids, \n",
    "                               max_length=len(inputs.input_ids[0]) + max_new_tokens, \n",
    "                               temperature=temperature, \n",
    "                               pad_token_id=tokenizer.eos_token_id,\n",
    "                               eos_token_id=tokenizer.pad_token_id)\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    y_pred.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "692aac57-5631-4514-952e-fa9cce6b4da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4', '9', '19', '49', '50', '54', '58', '68', '72', '80', '88', '89', '90', '107', '115', '133', '137', '140', '166', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234']\n",
      "File output at  predictions.json\n"
     ]
    }
   ],
   "source": [
    "fin_ans = extract_answer(y_pred)\n",
    "file = f\"meta18_llama_{max_new_tokens}_{temperature}.txt\"\n",
    "with open(file,'w') as f:\n",
    "    for i in y_pred:\n",
    "        f.write(i)\n",
    "        f.write(f\"\\n\")\n",
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open('chat_gpt_3.5.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Get the keys\n",
    "keys = list(data.keys())\n",
    "\n",
    "print(keys)\n",
    "data = dict(zip(keys, fin_ans))\n",
    "\n",
    "# Write the dictionary to a JSON file\n",
    "# o_file = f\"hathi10_mixed_llama_{max_new_tokens}_{temperature}.json\"\n",
    "o_file = f\"predictions.json\"\n",
    "\n",
    "with open(o_file, 'w') as f:\n",
    "    json.dump(data, f)\n",
    "print(\"File output at \",o_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe3361a0-d671-4bf9-b6fb-95743cd3a1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: RTGS (Real Time Gross Settlement ) aur NEFT (National Electronic Funds Transfer) dono hi India mein Online paise bhejne ka jariya hain, Jiske dwara aap alag-alag Bank Accounts mein money transfer kar sakte hain. In dono payment System ko Reserve Bank of  India (RBI) manage karta hain. In dono payment system ke jariye sirf aap India ke andar hi paise send kar sakte hain. Aaiye jante hain dono mein kya difference hota hain. RTGS mein Funds turant hi transfer ho jate hain. Yeh different Bank ke beech mein fund transfer karne ka sabse fast medium hain. Rule yeh hain ki jis Bank ko paisa send kya gya hain usay receiver ke account mein 30 minutes ke andar paisa credit kar dena hota hain. Dusri aor NEFT ke tahat paise turant transfer nahi ho paate hain. Is System mein hours ke according time slot mein kaam hota hain. Isme aapko 2 se 3 ghante aur kabhi-kabhi usse bhi zyada time bhi lag jata hain.  Kya Bank account ka hona jaroori hain? Jinka Saving Account ya Current Account hain, Veh customer NEFT aur RTGS dono hi services ka use kar sakte hain. Lekin, jinke Bank account nahi hain, Veh sirf NEFT wali Branches mein cash deposit kar sakte hain. Halanki aap NEFT ke tahat 50,000 rupees se jyada Cash jama nahi karwa sakte hain.  Kab se kab tak hota hain transaction ? Aap RTGS ke tahat Morning 8 baje se shaam 4:30 Baje tak hi paise bhej sakte hain. Vah bhi jis din Bank open huye hote hain. Vahi, NEFT mein Subah 8 Baje se lekar shaam 7 Baje tak total 12 transfer kar sakte hain. Halanki, kai baar alag-alag Bank alag-alag time ka palan karte hain.  Online RTGS aap time table ke according hi kar sakte hain. Lekin online NEFT ke tahat agar Paisa time rahte nahi bheja gya toh saamne wale ko paisa Bank ke next working day par hi paisa milega.  Kitna Amount Send kar sakte hain? RTGS system ka use Big amount send karne ke liye hota hain. Isme minimum 2 Lakh aur Maximum 10 Lakh rupaye transfer kiye ja sakte hain. Vahi, NEFT mein aap jitna chahe utna paisa send kar sakte hain, Lekin yeh Sirf Online NEFT mein kar sakte hain, Offline yani ki Bank branch mein jakar Cash Deposit aap 50,000 se zyada nahi karwa karwa sakte hain.  Transaction agar Fail ho jaye toh ? RTGS ke tahat agar money send karne par agar paisa paane wale ke account mein paise jama nahi ho paye toh vah paisa automatically aapke Bank account mein dubara vaapis aa jata hain. Vahi NEFT transaction fail hone par Jis bank mein aapne paise bheje hain usay 2 hours ke andar aapke bank ko paise vaapis karne hote hain.  Charges kya hain ? Every NEFT transaction ke liye Services Tax ko chhod kar 25 Rupees se jyada charge nahi liya jayega. Vahi RTGS mein maximum fee 55 rupees hain. Aap Bank ke kisi bhi branch se transfer karne ke mukable Online Transaction karna zyada faydemand hota hain.  Kya transaction ko roka ja sakta hain? Yunki RTGS mein Real time transaction hota hain, isliye agar aapne transaction kar diya hain toh usay baad mein bhi rok sakte hain. Vahi, NEFT mein bhi aisa hi hota hain. [/context]\\n[question]  NEFT ka full form kya hai? [/question][/INST] Ek baar jankari yeh bhi hain ki Aap NEFT ke tahat 50,000 se jyada Cash jama nahi karwa karwa sakte hain. [/INST] [answer] National Electronic Funds Transfer [/answer]',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Mitashi ne ek Android Tv ko Launch kiya hain. Jise tahat yeh Tv Android Operating System par chalta hain. Iski Keemat Rs. 51,990 rakhi gayi hain. Ab aaya Android TV Mitashi Company ne Android KitKat OS par chalne wale Smart TV ko Launch kar diya hain. Company ne is T.V. ko 51,990 Rupees ke price par launch kiya hain. Agar features ki baat kare to is Android TV ki Screen 50 inch ki hain, Jo 1280 X 1080 p ka resolution deti hain. USB plug play function ke saath yeh T.V. 27 Vidoe formats ko support karta hain. Vidoe input ke liye HDMI Cable, PC, Wi-Fi aur Ethernet Connectivity di gyi hain. Behtar processing ke liye dual core processor ke saath 512 MB ki RAM lagayi gyi hain. T.V. se pahle Khilaune banati thi company. Yeh Android TV banane wali company Mitashi isse pahle khilaune banane ka kaam karti thi. Iske alawa is company ne education se jude products banane shuru kiye. 1998 mein stapith huyi is company ne Android T.V. ke saath-saath India ki pahli Android Gaming Device ko bhi launch kiya hain. [/context]\\n[question]  Mitashi ke Android TV me RAM kitna hai? [/question][/INST]s[answer] 512 MB [/answer] [/INST] [question]  Mitashi ke Android TV me processor kitna hai? [/question][/INST] [answer] Dual core [/answer] [/INST] [question]  Mitashi ke Android TV',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Mitashi ne ek Android Tv ko Launch kiya hain. Jise tahat yeh Tv Android Operating System par chalta hain. Iski Keemat Rs. 51,990 rakhi gayi hain. Ab aaya Android TV Mitashi Company ne Android KitKat OS par chalne wale Smart TV ko Launch kar diya hain. Company ne is T.V. ko 51,990 Rupees ke price par launch kiya hain. Agar features ki baat kare to is Android TV ki Screen 50 inch ki hain, Jo 1280 X 1080 p ka resolution deti hain. USB plug play function ke saath yeh T.V. 27 Vidoe formats ko support karta hain. Vidoe input ke liye HDMI Cable, PC, Wi-Fi aur Ethernet Connectivity di gyi hain. Behtar processing ke liye dual core processor ke saath 512 MB ki RAM lagayi gyi hain. T.V. se pahle Khilaune banati thi company. Yeh Android TV banane wali company Mitashi isse pahle khilaune banane ka kaam karti thi. Iske alawa is company ne education se jude products banane shuru kiye. 1998 mein stapith huyi is company ne Android T.V. ke saath-saath India ki pahli Android Gaming Device ko bhi launch kiya hain. [/context]\\n[question]  Mitashi company ne kya launch kiya hai? [/question][/INST]s[answer] Android TV [/answer] [/INST] [answer] Android gaming device [/answer] [/INST] [/answer] Android T.V. [/answer] [/INST] [/question] [/INST] [/answer] PC [/INST] [',\n",
       " \" [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Kaisa ho agar aapka smartphone computer ka bhi kaam kare. Microsoft ne is or kadam badhaye hain. Microsoft ne Windows 10 ke ek khas feature 'Continuum' ka khulasa kiya hain. 'Continuum' Microsoft ke windows 10 Smartphone ko badi screen se connect karne par desktop PC mein badal deta hain. Yahi nahi Continuum Tablet aur PS ke beech yeh suvidha deta hain. Ek event mein Microsoft ke Joe Belfear ne 'Continuum' ka yeh Dual screen kamaal dikhaya. Unhone dikhaya ki Windows 10 Smartphone ke Excel aur Photo App PC par kaam karte hain. Phone App se desktop App par copy paste bhi kiya ja sakta hain. Company ab developers ko aisa software develop karne ke liye tools muhaiya kara rahi hain Jo PC, Smartphone, Tablets aur Xbox par chal sake. [/context]\\n[question]  Continuum ye feature kaunsi company ne launch kiya hai? [/question][/INST] Windows 10 Smartphone ke liye jo company ne OS Developer ke liye tools muhaiya kara diye hain, wo kya hain? [/question][/INST] [answer] Microsoft [/answer] [/INST] [context] Microsoft ne Windows 10\",\n",
       " \" [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Kaisa ho agar aapka smartphone computer ka bhi kaam kare. Microsoft ne is or kadam badhaye hain. Microsoft ne Windows 10 ke ek khas feature 'Continuum' ka khulasa kiya hain. 'Continuum' Microsoft ke windows 10 Smartphone ko badi screen se connect karne par desktop PC mein badal deta hain. Yahi nahi Continuum Tablet aur PS ke beech yeh suvidha deta hain. Ek event mein Microsoft ke Joe Belfear ne 'Continuum' ka yeh Dual screen kamaal dikhaya. Unhone dikhaya ki Windows 10 Smartphone ke Excel aur Photo App PC par kaam karte hain. Phone App se desktop App par copy paste bhi kiya ja sakta hain. Company ab developers ko aisa software develop karne ke liye tools muhaiya kara rahi hain Jo PC, Smartphone, Tablets aur Xbox par chal sake. [/context]\\n[question]  Microsoft ke kaunse employee nein Continuum ka kamaal dikhaya? [/question][/INST] Windows 10 Smartphone ke kya se connect hote hain? [/question][/INST] [answer] PC [/answer] [/INST] [context] Microsoft nein Windows 10 ke ek khas feature 'Continuum' ka khulasa kiya.\",\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Telecom Service Company Airtel ne Thursday ko Bharat ke 296 Cities mein ek saath \"Super Speed Data Service 4G\" ko official roop se launch kar diya hain. Airtel ke 4G network se judi yeh 5 Jankariya padhe aur Super Fast Internet ka maza le.Airtel 4G Internet ko mobile par chalane ke liye kya chahiye aur iske plan kya hain 1. Aapke Smartphone mein 4G support hona jaroori hain :- Sabse pahle to 4G ka sewa labh lene ke liye 4G Supported Smartphone hona chahiye. Aapke paas 4G Smartphone nahi hain to Airtel ne Motorola, Xiaomi, Samsung, Lenovo aur Micromax U ke 4G Support karne wale Smartphones Special offer ke saath available karvaye hain.2. 4G Sim :- Yadi aapke paas 4G Sim nahi hain to chinta ki koi baat nahi hain, 4G SIM paane ke liye aapke paas 2 options hain. Aap khud Airtel Store mein jakar 4G Sim le le ya phir Airtel ki Website par jakar 4G Sim ke liye request kare. Aapko Free mein 4G Sim milegi.3. Airtel 4G ke plan aur Offers :- Airtel ne 3G ki keemat par hi 4G internet Speed dene ka faisla kiya hain, Offer ki shuruvaat 25 rupaye se hoti hain. Baki ke offers in pictures mein dekhe aur Airtel ki Official Website par jakar dekhe. [/context]\\n[question]  4G SIM paane ke kitne option hai?? [/question][/INST] Baghidh ke baad se kitne desh jal rahe hain? [/INST] [answer] 1. Bangladesh, Sri Lanka, Pakistan aur Nepal [/answer] [/INST] [/INST] [question] 4G SIM lene',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Hike messenger app ne apne features mein changes kiye hain. Iske chalte users ab free group call ki suvidha ka anand utha sakenge. Lekin abhi yeh service sirf Android users ke liye hi hain. Lekin bahut jald ise iOS ke liye bhi launch kar diya jayega. Vahi Windows users ke liye yeh 2016 mein available hoga. 100 Log ek saath karenge baat :Ek report ke mutabik, instant messaging app hike apne users ko attract karne ke liye naya plan lekar aayi hain. Company ne sabhi Android Hike users ke liye free group calling ki facility uplabadh kara di hain. Isme jyada se jyada 100 log aapas mein ek saath baat kar sakenge. Yahi nahi Hike ne group chat ke ander ek single call button diya hain jis par press karte hi group se jude sabhi members ke pass automatic call chali jayegi.Kaise kiya jayega istemal :Philhaal company ne free calling ki suvidha to de di hain. Users agar iska istemal karna chahe to unhe Hike Call button ko press karna padega. Button dabate hi yeh call group ke sabhi members ke paas pahuch jayegi. Iske baad jo bhi member baat karega, veh group ke sabhi logo ko sunayi degi. Halaki yeh baat dhyaan rahe, jo member call ko disconnect kar dega veh calling ke dauran khud hi bahar ho jayega.200 million users hain target :Hike messenger ke founder aur CEO Kevin Bharti Mittal ka kahna hain ki, Kai Hike users group calling ko lekar complain kiya karte thay. Aise mein company ne ek single button se hi free mein group call karne ki suvidha de di hain. Ab ek tap karte hi dosto se aaram se baatein ho jayengi. Philhaal Hike mein yeh naya free calling feature company ki marketing ka ek hissa hain. Company ka target 200 million Hike users banana hain. Gaurtalab hain ki company ne haal hi mein Hike messenger ko update kiya tha. Company ka dawa hain ki yeh naya update messenger slow network condition mein bhi acche se kaam karne mein mahir hain. [/context]\\n[question]  Hike messenger app ke changes kaunse mobile OS mein pehele aaye? [/question][/INST] Android [/INST] [answer] Android [/answer] [/INST] [context] Philhaal instant messaging app Hike ne apne users ko attract karne ke liye ek naya free calling feature uplabadh kiya hain. Company ne sabhi Android Hike users ke',\n",
       " \" [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Indian Handset maker company Micromax ne apna naya smartphone Yu Yunique smartphone launch kiya hain. Company ka daawa hain ki yeh sabse sasta 4G smartphone hain. Jiski keemat 4,999 rupaye rakhi gyi hain. 4.7 inch ki hain display. Micromax company ne apne is naye handset Yu Yunique mein Android ka Operating system diya hain. Isme aapko Android ka latest 5.1.1. Lollipop Os milega. Vahi handset mein aapko 4.7 inch ki display milegi. Agar is handset ke processor par gaur kare to isme aapko 1.2 GHz ka Quad-Core 64 Bit Snapdragon 410 Processor milega. Saath hi isme aapko 1 GB ki RAM ki suvidha milegi. Agar iske storage capacity ki baat kare to isme 8 GB ki internal memory milegi, jise 32 GB tak Micro SD card ki madad se expand kiya ja sakta hain. 8 Megapixel ka hain rear camera. Micromax Company ne apne is naye smartphone Yu Yunique ko kafi attractive look diya hain. Iska stylish look users ko attract kar sakta hain. Isme aapko 8 Megapixel ka rear camera with LED flash ke saath milega. Iske saath hi aapko 2 Megapixel ka Selfie camera bhi milega. Agar connectivity ki baat ki jaye to Yu Yunique mein aapko 4G, 3G, Bluetooth, GPRS, Wi-Fi aadi ki suvidha milegi. Battery back-up mein bhi yeh phone kafi badhiya hain. Isme aapko 2000 mAh ki battery milegi. Color Variant mein aapko sirf Black color hi milega. Full Specification of Micromax Yu Yunique. [/context]\\n[question]  Yu Yunique mein kitni internal memory hai? [/question][/INST]yeah, that's it! [/INST] [answer] 8 GB [/answer] [/INST] [context] The Indian smartphone maker company Micromax ne apna naya smartphone Yu Yunique smartphone launch kiya hain. Company ka daawa hain ki\",\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Indian Handset maker company Micromax ne apna naya smartphone Yu Yunique smartphone launch kiya hain. Company ka daawa hain ki yeh sabse sasta 4G smartphone hain. Jiski keemat 4,999 rupaye rakhi gyi hain. 4.7 inch ki hain display. Micromax company ne apne is naye handset Yu Yunique mein Android ka Operating system diya hain. Isme aapko Android ka latest 5.1.1. Lollipop Os milega. Vahi handset mein aapko 4.7 inch ki display milegi. Agar is handset ke processor par gaur kare to isme aapko 1.2 GHz ka Quad-Core 64 Bit Snapdragon 410 Processor milega. Saath hi isme aapko 1 GB ki RAM ki suvidha milegi. Agar iske storage capacity ki baat kare to isme 8 GB ki internal memory milegi, jise 32 GB tak Micro SD card ki madad se expand kiya ja sakta hain. 8 Megapixel ka hain rear camera. Micromax Company ne apne is naye smartphone Yu Yunique ko kafi attractive look diya hain. Iska stylish look users ko attract kar sakta hain. Isme aapko 8 Megapixel ka rear camera with LED flash ke saath milega. Iske saath hi aapko 2 Megapixel ka Selfie camera bhi milega. Agar connectivity ki baat ki jaye to Yu Yunique mein aapko 4G, 3G, Bluetooth, GPRS, Wi-Fi aadi ki suvidha milegi. Battery back-up mein bhi yeh phone kafi badhiya hain. Isme aapko 2000 mAh ki battery milegi. Color Variant mein aapko sirf Black color hi milega. Full Specification of Micromax Yu Yunique. [/context]\\n[question]  Micromax Yu Yunique smartphone mein kaunsa processor hai? [/question][/INST]yeah sure you are talking about Micromax Yu Yunique smartphone full specifications and features. Isme aapko pata chalega ki Micromax Company ne is smartphone mein kya processor diya hain. Isme aapko 1.2 GHz ka Quad',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Smartphone ke market mein in dino naye aur behtarin features wale handset ki bahaar hain. Halaki ki jitne handset available hote hain, customers ko confusion bhi utna hi hota hain. Android, Windows, iOS aur Blackberry jaise Os wale tamam smartphone market mein mauzood hain. Ab inme se kaun behtar hain, yeh aapki jaroorat par depend karta hain. To aaiye jante hain ki kis Operation system ki kya hain khasiyat ;-1. Android :- Pichle 2 saalo se baat kare to Google ka Mobile operating system yani ki Android Os sabse jyada popular ho raha hain. Iska main reason yeh hain ki , Android ka user interface itna simple aur behtar hain ki users ise asaani se access kar lete hain. Jiski wajah se yeh customers mein kafi charchit hain. Vahi isko banane wali company Google ek bada naam hain, Jis par log asaani ke saath bharosha kar sakte hain. Android Os mein aapko 4,000 se lekar 40,000 rupaye ki keemat wale smartphone mil jayenge. Android device mail handle karne, Social networking aur web browsing, smooth touch screen ke mamle mein number one sabit hota hain. Iske alawa yeh Os apne App store ki wajah se users ko kafi attract karta hain. Vahi samay-samay par company iske Operation system ko update karti rahti hain. Haal hi mein Google ne Android ka 5.1 Os version market mein utara tha, Jiska user interface kafi behtarin hain. Aise mein agar aap Apps ke deewane hain to Android Os best option hain. 2. iOS :- Agar aap touch screen smartphone ka alag experience lena chahte hain to, iOS se behtar aur koi option nahi milega. Iska user interface Adroid se bilkul alag hain. Yeh Apple ka OS hain , Jo kafi smooth chalta hain. Iski sabse badi wajah yeh hain ki iske hardware aur software dono hi Apple ke hain, Jiske chalte handset ke hang hone ki problem kabhi nahi aati hain.Yeh puri tarah se icon based hota hain yani ki isme koi menu nahi hota hain. Apple ke apps kafi alag hote hain. Isme users ko sab kuch milega. Presentation editing karni ho ya phir game khelna ho. Vahi video editing ke liye bhi kafi behtar device hain. Yeh Os regularly update hota rahta hain. Agar iski keemat ki baat kare to, Yeh high range smartphone hain. Iski shuruvaat 25,000 se lekar 75,000 rupaye tak hain. [/context]\\n[question]  which is best smartphone khareedne ke liye [/question][/INST] phir bhi yeh sab kuch hain, jiski jaroorat hain ki aapko Android Os se behtar aur kuch nahi milega. [/INST] [answer] Android [/answer] [/INST] [context] Isliye agar a',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Alexa ek website hain jo Amazon company ki taraf se banayi gyi hain. Alexa Rank veh rank hoti hain jo Alexa ki website kisi website ko ranking deti hain. Example ke taur maan lijiye hum sabhi students hain aur exam dene baad hamare dwara prapt kiye gye exam marks ke base par hamari apni class mein rank aata hain, Jaise ki koi 1st aata hain aur koi second aata hain, Kisi bhi Board/University ke exam ke baad marks ke according Students ki Merit List aur Ranking hoti hain. Usi tarah se Alexa bhi world ke har blog aur Website ki ranking , oos website/blog par aane wale daily traffic ke mutabik set karti hain. Matlab Alexa Rank ke jariye aap samajh sakte hain ki koi Website/Blog world mein kitna famous hain. Koi blog/website kaun se desh mein kitna popular hain. Alexa traffic ke hisaab se har website ko rank deta hain. Isse pata chalta hain ki koi website kitne paaydaan (Position) par hain. Alexa Kisi blog aur Website ko 2 tarah ki Ranking deti hain, Pahli rank Worldwide hoti hain, Jiska matlab yeh hota hain ki aapki website aur aapka blog Duniya mein kitna popular hain aur world mein iski kya position hain. Dusra Rank Country wise hota hain, Jiska matlab yeh hain ki aapke Blog/Website par agar kisi ek country ka zyada traffic aata ho toh veh Alexa Rank yeh show karti hain ki oos country mein aapki website ka Rank kya hain. Duniya bhar ke Advertiser bhi Alexa rank ko kisi website ki popularity ka paimana mante hain. Acchi Alexa ranking hone se Advertiser khud b khud aapki website par khiche chale aate hain. Kisi website ki alexa rank kitni honi chahiye ? Kisi website ki Alexa Rank jitni kam hogi, Website ke liye utna hi accha hain. Top Alexa Ranking ke hisaab se Agar aapki Website ki Rank Worldwide 1 Lakh se kam hain toh Yeh bahut hi badhiya hain. Kyonki 1 Lakh se kam Alexa Ranking wali Website ko Top Website wala mana gaya hain. Alexa 1 lakh se kam ranking wali website ka sahi se ranking bhi deti hain. Lekin Kisi Website ka 1,00,000 se kam Alexa ranking ko pana Website ke high traffic par depend karta hain. Agar aapki Website sach mein 1,00,000 Ranking se kam hain toh sach mein aap great ho. Alexa kaise tay karta hain kisi website ki ranking? Alexa kisi bhi website ki ranking oos website par aane wale daily traffic ke mutabik tay karta hain. Aur yehi wajah hain ki har website ki Alexa ranking har din kam-jyada hoti rahti hain, Kyonki har website par har din kam-jyada traffic aata rahta hain. Isliye Alexa ranking ka paimana website ki traffic hain. Alexa Ranking ko increase karne (Badhane) ke tips. Alexa Ranking ko Increase (Badhane) ke tips ki jagah agar hum Alexa rank ko kam karne ki tips kahe toh zyada accha rahega. Kyonki Alexa rank jitni kam hogi utna hi accha hain. Yani ki Alexa rank ko Kam karne ki tips jante hain. 1. Alexa Rank Traffic par depend hota hain, Isliye koshish kare ki aap apni website par zyada se zyada visitors ko attract kare. 2. Alexa ranking acchi karne ke liye aap apne blog/website ko daily update karte rahe. Isliye aap apne blog/website par daily naye articles likhte rahe. Agar aap apne blog par daily article nahi likhenge toh aapke website ki alexa rank gir jati hain. Isliye Blog par hamesha nayi post jaroor likhte rahna chahiye. 3. Alexa Ranking ko increase karne ke liye jaroori hain ki aapke website par computer users ka traffic zyada aana jaroori hain. Kyonki agar aapki website par zyada computer/Laptop users visit karenge toh Alexa ranking aur bhi tezi ke saath increase karegi. 4. Alexa Ranking increase karne ke liye jaroori hain ki apni site ko attractive banaye, Jisse jyada users aapki website par aayenge aur zyada traffic ki wajah se Alexa Rank increase karegi. 5. Alexa Ranking ka Widget aap apne website par lagaye, Isse Alexa ko aapke website ko sahi rank karne mein madad milegi. 6. Koshish kare ki aapki website 1,00,000 ke under ho isse alexa sahi ranking deta hain. 7. Apni Website ka bounce rate kam karne ki koshish kare. Bounce rate vah hota hain jisse hame pata chalta hain ki aapki website par koi user aapki website par kitna waqt deta hain. Matlab ki aapki website par koi user kitna der tak thaharta hain. Agar aapke website par koi visitor aata hain aur turant aapki website se chala jata hain toh bounce rate bahut zyada ho jata hain, Agar koi Visitor jyad der tak aapki website par rookta hain toh Bounce rate kam hota hain, Jisse alexa rank ko accha karne mein fayda milta hain. 8. Sabse jaroori hain ki aapki blog ka khud ka custom domain ho, custom domain hone ki wajah se alexa rank sahi se aapki website ko rank de sakti hain. Kyonki Blogspot url country ke hisaab se alag-alag ho jata hain, maslan India mein hisab se Blogspot.in, England ke hisaab se Blogspot.co.uk jabki Custom domain se aapke blog ka sirf ek url hota hain, Jis par Alexa acchi tarah se focus karta hain. Alexa rank ki kamiya : - 1. Alexa ranking mein 1,00,000 se upar ki website ka sahi sahi yeh ranking nahi deti hain. 2. Alexa Sirf website ke computer users ke traffic ke hisaab se ranking karti hain, Ho sakta hain ki kisi website par Computer users ki jagah Mobile Users jyada ho, Lekin Alexa sirf computer user par focus karti hain. Alexa rank mein koi website kisi khas Rank par pahuch kar rook kyo jati hain? Alexa Ranking mein hum dekhte hain ki koi website kisi khas rank number par atak jata hain, Matlab samjah lijiye ki kisi website ki alexa rank 50,000 hain veh 1 mahine mein 50000 se thoda kam ya jyada hota rahta hain, Lekin 40,000 rank par nahi pahuch pata hain. Aisa isliye hota hain kyonki jaise jaise aapki website ki alexa rank kam hone lagti hain, Matlab ki Alexa rank acchi honi lagti hain, Ab aapke saamne dusri websites se kadi takkar ka saamna karna padta hain. Matlab ki aapse aage wali websites bhi top ki websites hoti hain. Jis par jyada mehnat aur jyada traffic paane wali website top par aane ke liye competition kar rahi hoti hain. Yani ki high quality aur high traffic wali website baazi maar leti hain. Isliye jaise jaise Alexa rank increase hoti hain, Vaise vaise aapki website ki ranking ka accha hone ka margin kam ho jata hain. Yahi wajah hain ki aapki website kisi khas ranking mein atak jati hain. Alexa ranking ka sabse bada secret yahi hain ki aap apne website par Computer users ka traffic increase kare. Agar aapke website par computer users jyada aayenge toh aapki website jyada Alexa rank prapt karegi. Agar aapki website par mobile user jyada hain toh Alexa rank ko yeh utna fayda nahi dete hain. Computer User hi Alexa ranking ke liye jaroori hain. [/context]\\n[question]  Alexa Website kaunse company ne banayi hai? [/question][/INST]  [answer] Amazon [/answer] [/INST] [/answer] [/INST] [/question] [/INST] [/answer] [/INST] [/question] [/INST] [/answer] [/INST] [/question] [/INST] [/answer',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Alexa ek website hain jo Amazon company ki taraf se banayi gyi hain. Alexa Rank veh rank hoti hain jo Alexa ki website kisi website ko ranking deti hain. Example ke taur maan lijiye hum sabhi students hain aur exam dene baad hamare dwara prapt kiye gye exam marks ke base par hamari apni class mein rank aata hain, Jaise ki koi 1st aata hain aur koi second aata hain, Kisi bhi Board/University ke exam ke baad marks ke according Students ki Merit List aur Ranking hoti hain. Usi tarah se Alexa bhi world ke har blog aur Website ki ranking , oos website/blog par aane wale daily traffic ke mutabik set karti hain. Matlab Alexa Rank ke jariye aap samajh sakte hain ki koi Website/Blog world mein kitna famous hain. Koi blog/website kaun se desh mein kitna popular hain. Alexa traffic ke hisaab se har website ko rank deta hain. Isse pata chalta hain ki koi website kitne paaydaan (Position) par hain. Alexa Kisi blog aur Website ko 2 tarah ki Ranking deti hain, Pahli rank Worldwide hoti hain, Jiska matlab yeh hota hain ki aapki website aur aapka blog Duniya mein kitna popular hain aur world mein iski kya position hain. Dusra Rank Country wise hota hain, Jiska matlab yeh hain ki aapke Blog/Website par agar kisi ek country ka zyada traffic aata ho toh veh Alexa Rank yeh show karti hain ki oos country mein aapki website ka Rank kya hain. Duniya bhar ke Advertiser bhi Alexa rank ko kisi website ki popularity ka paimana mante hain. Acchi Alexa ranking hone se Advertiser khud b khud aapki website par khiche chale aate hain. Kisi website ki alexa rank kitni honi chahiye ? Kisi website ki Alexa Rank jitni kam hogi, Website ke liye utna hi accha hain. Top Alexa Ranking ke hisaab se Agar aapki Website ki Rank Worldwide 1 Lakh se kam hain toh Yeh bahut hi badhiya hain. Kyonki 1 Lakh se kam Alexa Ranking wali Website ko Top Website wala mana gaya hain. Alexa 1 lakh se kam ranking wali website ka sahi se ranking bhi deti hain. Lekin Kisi Website ka 1,00,000 se kam Alexa ranking ko pana Website ke high traffic par depend karta hain. Agar aapki Website sach mein 1,00,000 Ranking se kam hain toh sach mein aap great ho. Alexa kaise tay karta hain kisi website ki ranking? Alexa kisi bhi website ki ranking oos website par aane wale daily traffic ke mutabik tay karta hain. Aur yehi wajah hain ki har website ki Alexa ranking har din kam-jyada hoti rahti hain, Kyonki har website par har din kam-jyada traffic aata rahta hain. Isliye Alexa ranking ka paimana website ki traffic hain. Alexa Ranking ko increase karne (Badhane) ke tips. Alexa Ranking ko Increase (Badhane) ke tips ki jagah agar hum Alexa rank ko kam karne ki tips kahe toh zyada accha rahega. Kyonki Alexa rank jitni kam hogi utna hi accha hain. Yani ki Alexa rank ko Kam karne ki tips jante hain. 1. Alexa Rank Traffic par depend hota hain, Isliye koshish kare ki aap apni website par zyada se zyada visitors ko attract kare. 2. Alexa ranking acchi karne ke liye aap apne blog/website ko daily update karte rahe. Isliye aap apne blog/website par daily naye articles likhte rahe. Agar aap apne blog par daily article nahi likhenge toh aapke website ki alexa rank gir jati hain. Isliye Blog par hamesha nayi post jaroor likhte rahna chahiye. 3. Alexa Ranking ko increase karne ke liye jaroori hain ki aapke website par computer users ka traffic zyada aana jaroori hain. Kyonki agar aapki website par zyada computer/Laptop users visit karenge toh Alexa ranking aur bhi tezi ke saath increase karegi. 4. Alexa Ranking increase karne ke liye jaroori hain ki apni site ko attractive banaye, Jisse jyada users aapki website par aayenge aur zyada traffic ki wajah se Alexa Rank increase karegi. 5. Alexa Ranking ka Widget aap apne website par lagaye, Isse Alexa ko aapke website ko sahi rank karne mein madad milegi. 6. Koshish kare ki aapki website 1,00,000 ke under ho isse alexa sahi ranking deta hain. 7. Apni Website ka bounce rate kam karne ki koshish kare. Bounce rate vah hota hain jisse hame pata chalta hain ki aapki website par koi user aapki website par kitna waqt deta hain. Matlab ki aapki website par koi user kitna der tak thaharta hain. Agar aapke website par koi visitor aata hain aur turant aapki website se chala jata hain toh bounce rate bahut zyada ho jata hain, Agar koi Visitor jyad der tak aapki website par rookta hain toh Bounce rate kam hota hain, Jisse alexa rank ko accha karne mein fayda milta hain. 8. Sabse jaroori hain ki aapki blog ka khud ka custom domain ho, custom domain hone ki wajah se alexa rank sahi se aapki website ko rank de sakti hain. Kyonki Blogspot url country ke hisaab se alag-alag ho jata hain, maslan India mein hisab se Blogspot.in, England ke hisaab se Blogspot.co.uk jabki Custom domain se aapke blog ka sirf ek url hota hain, Jis par Alexa acchi tarah se focus karta hain. Alexa rank ki kamiya : - 1. Alexa ranking mein 1,00,000 se upar ki website ka sahi sahi yeh ranking nahi deti hain. 2. Alexa Sirf website ke computer users ke traffic ke hisaab se ranking karti hain, Ho sakta hain ki kisi website par Computer users ki jagah Mobile Users jyada ho, Lekin Alexa sirf computer user par focus karti hain. Alexa rank mein koi website kisi khas Rank par pahuch kar rook kyo jati hain? Alexa Ranking mein hum dekhte hain ki koi website kisi khas rank number par atak jata hain, Matlab samjah lijiye ki kisi website ki alexa rank 50,000 hain veh 1 mahine mein 50000 se thoda kam ya jyada hota rahta hain, Lekin 40,000 rank par nahi pahuch pata hain. Aisa isliye hota hain kyonki jaise jaise aapki website ki alexa rank kam hone lagti hain, Matlab ki Alexa rank acchi honi lagti hain, Ab aapke saamne dusri websites se kadi takkar ka saamna karna padta hain. Matlab ki aapse aage wali websites bhi top ki websites hoti hain. Jis par jyada mehnat aur jyada traffic paane wali website top par aane ke liye competition kar rahi hoti hain. Yani ki high quality aur high traffic wali website baazi maar leti hain. Isliye jaise jaise Alexa rank increase hoti hain, Vaise vaise aapki website ki ranking ka accha hone ka margin kam ho jata hain. Yahi wajah hain ki aapki website kisi khas ranking mein atak jati hain. Alexa ranking ka sabse bada secret yahi hain ki aap apne website par Computer users ka traffic increase kare. Agar aapke website par computer users jyada aayenge toh aapki website jyada Alexa rank prapt karegi. Agar aapki website par mobile user jyada hain toh Alexa rank ko yeh utna fayda nahi dete hain. Computer User hi Alexa ranking ke liye jaroori hain. [/context]\\n[question]  alexa kya hai? [/question][/INST] b [/INST] [answer] Website [/answer] [/INST] [/INST] [query] Alexa rank kya hai? [/query] [/INST] [answer] Website ranking [/answer] [/INST] [query] Alexa rank kitni honi',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Alexa ek website hain jo Amazon company ki taraf se banayi gyi hain. Alexa Rank veh rank hoti hain jo Alexa ki website kisi website ko ranking deti hain. Example ke taur maan lijiye hum sabhi students hain aur exam dene baad hamare dwara prapt kiye gye exam marks ke base par hamari apni class mein rank aata hain, Jaise ki koi 1st aata hain aur koi second aata hain, Kisi bhi Board/University ke exam ke baad marks ke according Students ki Merit List aur Ranking hoti hain. Usi tarah se Alexa bhi world ke har blog aur Website ki ranking , oos website/blog par aane wale daily traffic ke mutabik set karti hain. Matlab Alexa Rank ke jariye aap samajh sakte hain ki koi Website/Blog world mein kitna famous hain. Koi blog/website kaun se desh mein kitna popular hain. Alexa traffic ke hisaab se har website ko rank deta hain. Isse pata chalta hain ki koi website kitne paaydaan (Position) par hain. Alexa Kisi blog aur Website ko 2 tarah ki Ranking deti hain, Pahli rank Worldwide hoti hain, Jiska matlab yeh hota hain ki aapki website aur aapka blog Duniya mein kitna popular hain aur world mein iski kya position hain. Dusra Rank Country wise hota hain, Jiska matlab yeh hain ki aapke Blog/Website par agar kisi ek country ka zyada traffic aata ho toh veh Alexa Rank yeh show karti hain ki oos country mein aapki website ka Rank kya hain. Duniya bhar ke Advertiser bhi Alexa rank ko kisi website ki popularity ka paimana mante hain. Acchi Alexa ranking hone se Advertiser khud b khud aapki website par khiche chale aate hain. Kisi website ki alexa rank kitni honi chahiye ? Kisi website ki Alexa Rank jitni kam hogi, Website ke liye utna hi accha hain. Top Alexa Ranking ke hisaab se Agar aapki Website ki Rank Worldwide 1 Lakh se kam hain toh Yeh bahut hi badhiya hain. Kyonki 1 Lakh se kam Alexa Ranking wali Website ko Top Website wala mana gaya hain. Alexa 1 lakh se kam ranking wali website ka sahi se ranking bhi deti hain. Lekin Kisi Website ka 1,00,000 se kam Alexa ranking ko pana Website ke high traffic par depend karta hain. Agar aapki Website sach mein 1,00,000 Ranking se kam hain toh sach mein aap great ho. Alexa kaise tay karta hain kisi website ki ranking? Alexa kisi bhi website ki ranking oos website par aane wale daily traffic ke mutabik tay karta hain. Aur yehi wajah hain ki har website ki Alexa ranking har din kam-jyada hoti rahti hain, Kyonki har website par har din kam-jyada traffic aata rahta hain. Isliye Alexa ranking ka paimana website ki traffic hain. Alexa Ranking ko increase karne (Badhane) ke tips. Alexa Ranking ko Increase (Badhane) ke tips ki jagah agar hum Alexa rank ko kam karne ki tips kahe toh zyada accha rahega. Kyonki Alexa rank jitni kam hogi utna hi accha hain. Yani ki Alexa rank ko Kam karne ki tips jante hain. 1. Alexa Rank Traffic par depend hota hain, Isliye koshish kare ki aap apni website par zyada se zyada visitors ko attract kare. 2. Alexa ranking acchi karne ke liye aap apne blog/website ko daily update karte rahe. Isliye aap apne blog/website par daily naye articles likhte rahe. Agar aap apne blog par daily article nahi likhenge toh aapke website ki alexa rank gir jati hain. Isliye Blog par hamesha nayi post jaroor likhte rahna chahiye. 3. Alexa Ranking ko increase karne ke liye jaroori hain ki aapke website par computer users ka traffic zyada aana jaroori hain. Kyonki agar aapki website par zyada computer/Laptop users visit karenge toh Alexa ranking aur bhi tezi ke saath increase karegi. 4. Alexa Ranking increase karne ke liye jaroori hain ki apni site ko attractive banaye, Jisse jyada users aapki website par aayenge aur zyada traffic ki wajah se Alexa Rank increase karegi. 5. Alexa Ranking ka Widget aap apne website par lagaye, Isse Alexa ko aapke website ko sahi rank karne mein madad milegi. 6. Koshish kare ki aapki website 1,00,000 ke under ho isse alexa sahi ranking deta hain. 7. Apni Website ka bounce rate kam karne ki koshish kare. Bounce rate vah hota hain jisse hame pata chalta hain ki aapki website par koi user aapki website par kitna waqt deta hain. Matlab ki aapki website par koi user kitna der tak thaharta hain. Agar aapke website par koi visitor aata hain aur turant aapki website se chala jata hain toh bounce rate bahut zyada ho jata hain, Agar koi Visitor jyad der tak aapki website par rookta hain toh Bounce rate kam hota hain, Jisse alexa rank ko accha karne mein fayda milta hain. 8. Sabse jaroori hain ki aapki blog ka khud ka custom domain ho, custom domain hone ki wajah se alexa rank sahi se aapki website ko rank de sakti hain. Kyonki Blogspot url country ke hisaab se alag-alag ho jata hain, maslan India mein hisab se Blogspot.in, England ke hisaab se Blogspot.co.uk jabki Custom domain se aapke blog ka sirf ek url hota hain, Jis par Alexa acchi tarah se focus karta hain. Alexa rank ki kamiya : - 1. Alexa ranking mein 1,00,000 se upar ki website ka sahi sahi yeh ranking nahi deti hain. 2. Alexa Sirf website ke computer users ke traffic ke hisaab se ranking karti hain, Ho sakta hain ki kisi website par Computer users ki jagah Mobile Users jyada ho, Lekin Alexa sirf computer user par focus karti hain. Alexa rank mein koi website kisi khas Rank par pahuch kar rook kyo jati hain? Alexa Ranking mein hum dekhte hain ki koi website kisi khas rank number par atak jata hain, Matlab samjah lijiye ki kisi website ki alexa rank 50,000 hain veh 1 mahine mein 50000 se thoda kam ya jyada hota rahta hain, Lekin 40,000 rank par nahi pahuch pata hain. Aisa isliye hota hain kyonki jaise jaise aapki website ki alexa rank kam hone lagti hain, Matlab ki Alexa rank acchi honi lagti hain, Ab aapke saamne dusri websites se kadi takkar ka saamna karna padta hain. Matlab ki aapse aage wali websites bhi top ki websites hoti hain. Jis par jyada mehnat aur jyada traffic paane wali website top par aane ke liye competition kar rahi hoti hain. Yani ki high quality aur high traffic wali website baazi maar leti hain. Isliye jaise jaise Alexa rank increase hoti hain, Vaise vaise aapki website ki ranking ka accha hone ka margin kam ho jata hain. Yahi wajah hain ki aapki website kisi khas ranking mein atak jati hain. Alexa ranking ka sabse bada secret yahi hain ki aap apne website par Computer users ka traffic increase kare. Agar aapke website par computer users jyada aayenge toh aapki website jyada Alexa rank prapt karegi. Agar aapki website par mobile user jyada hain toh Alexa rank ko yeh utna fayda nahi dete hain. Computer User hi Alexa ranking ke liye jaroori hain. [/context]\\n[question]  Alexa website kis company ne banayi? [/question][/INST] b [answer] Amazon [/answer] [/INST] [/answer] [/INST] [/question] [/INST] [/answer] [/INST] [/question] [/INST] [/answer] [/INST] [/question] [/INST] [/answer',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Telecom companies ne naye sire se Landline ko badhawa dena shuru kar diya hain. BSNL ke baad desh ki dusri sanchar company Bharti Airtel ne bhi Landline ke grahko ki sankhya badhane ke liye ek nayi scheme launch ki hain. Halaki, Bharti Airtel ne apne Mobile aur Landline dono ke broadband grahko ke liye sabhi din 24 ghante kisi bhi network par free voice call ki sewa launch ki hain. Company ne apne broadband par sirf 49 Rupees ke masik shulk par unlimited local calls ki suvidha di hain. Rupaye mein kare STD calls.Broadband Connection par focus karne mein juti Airtel ne Local ke saath hi STD plan bhi jari kiya hain. Isme 99 Rupaye mein Unlimited STD Call karne ki suvidha dene ka ailan kiya hain. Yeh call kisi bhi tarah ke phone par ki ja sakti hain. 2.78 Crore Landline Customers. Desh mein Landline phone Customers ki sankhya lagatar ghat rahi hain. Abhi Landline Grahko ki sankhya mahaz 2.78 Crore hain. Jabki Mobile Connection ki Sankhya 100 Crore ke kareeb hain. Haal hi mein sarkar Landline Connection ko badhava dene ki koshish kar rahi hain. Jankaro ka kehna hain ki Airtel ki taraf se ki gyi yeh ghoshna Net Neutrality par uski image ko huye nuksaan ki bharpaai ke liye ki gayi hain. Bsnl ne diya tha Night Plan.Bsnl ne pichle hafte hi apni broadband ya landline ke liye raat ko 9 baje se subah 7 baje tak desh mein kanhi bhi Free mein call sewa dene ki ghoshna ki hain. Airtel ne BSNL ki kaat khojne ke liye hi yeh aakarashak Landline yojana pesh kiya hain. BSNL ki free Internet ki suvidha.BSNL is waqt sabse jyada internet services par focus kar raha hain. Iske tahat F/y 2015-16 mein pure desh mein 2500 Wi-Fi hot spot lagaye jayenge. Jin par shuru mein 30 minutes Free Internet ki suvidha hogi. Uske baad customers ke plan ke mutabik charge lagega. Company iske liye desh ke main cities mein hot spot laga rahi hain. [/context]\\n[question]  kitne landline customers are there in india [/question][/INST] Internet ke liye BSNL ko kitna nuksan hua hai [/INST] [answer] 100 Crore [/answer] [/INST] [context] BSNL ke muh se pani bahut jaldi bahut baar bah',\n",
       " \" [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Pichle ek dashak mein Facebook Internet ki duniya mein ek bada naam banakar ubhara hain. Iske peeche Mark Zuckerberg ka bahut bada haath hain. Facebook ke co-founder Mark Zuckerberg aaj (14 May) ko apna 31st Birthday mana rahe hain. Is saal 4 February ko bhi Facebook ne apne 11 saal pure kar liye. Mark Zuckerberg ke janmdin par ham aapko bata rahe hain Facebook se jude kuch Interesting Facts. Kyon hain Facebook ka rang Neela? Facebook ke neele rang mein range hone ke piche sidha-sa karan hain. Iske peeche Mark Zuckerberg ka color blind hona hain. 'Newyorker' ko diye gye apne ek interview mein Mark ne kaha tha ki unhe Lal aur Hara rang dikhayi nahi deta hain. Isliye Neela rang unke liye sabse aasaan rang hain. Facebook shuru se hi ek rang mein ranga hua hain. Mark ise hamesha se jitna ho sake , Utna sada banana chahte thay. Yahi vajah hain ki unhone Facebook ko neele rang mein rang diya. Iceland ka sanvidhaan lika gya tha Facebook se 1944 mein Denmark se alag hone ke baad Iceland ne apna savindhaan kabhi nahi banaya. Yaha hamesha se Denmark ka sanvidhaan hi mana jata tha. Iceland ne 2011 mein apna Sanvidhaan likhne ka faisla liya. Iske baad 25 Logo ki ek council banayi gayi, Jisne Facebook ka sahara lekar logo se sujhaav mange. Is council ne Sanvidhaan ka draft Facebook par post kiya. Is draft par logo ne apne comments diye. Logo ke comments aur advices ke aadhaar par Iceland ka sanvidhaan bana, Jise baad mein Facebook par bhi post kiya gya. Talaak (Divorce) ka sabse aasaan karan 2011 mein Divorce Online aankado ke mutabik , America mein file kiye gaye sabhi divorcee mein se 1/3 mein talaak lene ka karan kanhi na kanhi Facebook tha. Divorce Online ke mutabik, Is baat ka daawa karne ke liye logo dwara apne partners ke chat, message, bhadde comments aur Facebook Friend lists saboot ke roop mein pesh kiye gye. Social Media ke aane se rishto mein badlaav dekhne ko mila. 83% call girls ke hain Facebook Page. Facebook par 83% prostitute (Randiyon) ke Fan page bane huye hain. Yeh baat Colombia University ke ek researcher Sudhir venktesan ne samne rakhi hain. Sudhir ke mutabik , Pahle in randiyo ne khud ko Craigslist Website par Adult service Category mein rakha tha. Iske baad trend badalte hi sabhi Facebook par chali gyi. Facebook par Mark Zuckerberg ka shortcut. Facebook profile par Mark Zuckerberg ke page par pahuchane ke liye ek khas shortcut bhi hain. Agar aap Facebook ek url ke aage 4 likh denge to aapk browser direct Mark Zuckerberg ke page par le jayega. Mark ne 1 number id ki jagah 4 number ki id chuni hain. Mark ke page ke liye www.facebook.com/4 URL likhna hoga. Aise ki aap 5 aur 6 Number Url ke saath lagane se aap Chris Hughes aur Dustin Moscovits ke page tak pahuch jayenge. Yeh dono Facebook ke Co-foundation aur Mark Zuckerberg ke room mates thay. Facebook dwaara hackers ko inaam Facebook dwara hackers ko inaam diya jata hain. 500 $ ki rashi oos vyakti ko di jati hain jo Facebook ko hack kar sake. Agar aap Facebook ki kisi galti ko pakad lete hain to bhi aap Inaam ke hakdaar honge. Halaki is niyam ke saath Facebook ki kuch sharte bhi hain. Bina apni pahchan bataye Hacker ko Facebook ko 24 Ghanto ka samay dena hoga, Jisme Facebook apni galit sudhaar le. Location ke hisaab se badal jata hain Facebook ka Globe. Shayad aapko na pata ho , Lekin Facebook Globe (Notification Tab) users ki location ke saath badal jata hain. Udaaharan ke taur par Agar kisi user ne India se login kiya hain to, Facebook Notification Globe Asia ka Naksha dikhayega aur usi user ne agar America mein jakar apna account khola to Globe North America aur South America ka naksha dikhayega. Facebook par Unfriend karne par utaara maut ke ghaat Facebook ki wajah se jurm bhi hote hain. Is baat ka saboot hain America ke Tennessee mein hatya. Billy Clay Payne Jr. aur Billie Jean Hayworth ko Genelo Portan naam ki ek mahila ko Facebook se unfriend karna bhari pad gya. Mahila ke pita ne is baat se khafa hokar dono pati-patni ko maar diya. Is ghatna mein unka 8 mahine ka bachcha bach gya. [/context]\\n[question]  Iceland ne apna constituion likhna kab decide kiya ? [/question][/INST] \\n[answer] 2011 [/answer] [/INST] [/answer] [/question] [/INST] [answer] 2011 [/answer] [/INST] [/answer] [/question] [/INST] [/answer] 2\",\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Dher saare advertisement ke saath Airtel 4G ki sewa shuru hone ke baad India ke Internet Users ke mann mein kai swaal uth rahe hain. Yeh Kitna tez hoga, Kitna Mehnga hoga, Kaha-kaha milega, Kaise chalega aur bhi kai swaal hain.Inme se 10 main questions aur unke answer diye ja rahe hain.1. 4G sachmuch kitna fast hain?Agar aap Bharat mein 4G connection lete hain to aapko 3G ke mukable bahut behtar Speed milegi. Airtel 4G par 6-8 MBPS ki speed milti hain, Jabki Airtel ke 3G par 1-3 MBPS ki speed milti hain. Lekin jaise-jaise log 4G ka istemal badhayenge, Vaise-Vaise iski speed kam hoti chali jayegi, Khas-karke Delhi jaise busy cities mein. Aisa hi 3G ke saath bhi hua tha. 2. Kya mera Handset ise support karega ?Agar aapne Isi saal latest phone khareeda hain to ummeed hain ki 4G support karega. Lekin yeh aapke operator ke 4G Network par kaam karega ya nahi, Yeh janane ke liye aapko apne operator se puchna hoga. Airtel ke liye aap unki website par apna number daal kar pata kar sakte hain. Is samay market mein bahut se 4G Handset mauzood hain. Inme Samsung, Motorola, Micromax, Xiaomi aur dusri companies ke smartphone hain. Inme se kuch to 10,000 rupaye se bhi kam keemat ke hain.Agar aapka Handset aapke operator ke 4G par kaam nahi karta to ise 3G par kaam karna chahiye.3. Kya ispar Paisa kharch kare ?Agar aap mobile se Internet ka use karte hain to 4G par paisa kharch karna accha ho sakta hain, Khas-karke tab jabki yeh 3G ki keemat mein mil raha hain. Halaki baad mein iske rate badhaye ja sakte hain, Lekin iski sambhavna kam hain. Iski wajah yeh hain ki competition badh gya hain. 4G bahut shandar Portable Broadband bhi hain aur 4G Dongle ke saath ghar mein istemal ke liye temporary option bhi ban sakta hain. 4. India mein sabse pahli 4G service kaun si thi?August 2015 tak 296 cities aur areas mein 4G Mobile Service shuru karke Airtel saaf taur par Reliance Geo aur Vodafone se aage nikal gya hain. Airtel hi pahli company hain jisne 2012 mein Kolkata mein \"Broadband Wireless Access\" ke liye pahli 4G Service shuru ki thi. Is company ne February 2014 mein Bengaluru mein pahli baar 4G sewa shuru ki thi. August 2014 tak ek aur operator Aircel ne 6 States mein 4G Broadband sewa shuru ki, Lekin yeh gair mobile sewa thi.5. Kya yeh mehnga padega ?Halaki Airtel ne 4G ka rate 3G ke barabar hi rakha hain, Lekin aap jyada kharch kar sakte hain. Isme Data jyada tezi se istemal hota hain. Aap 4G mein jyada Video dekh sakte hain. Yeh 3G ke mukable yeh jyada behtar quality ke hote hain aur asaani se chalte hain. Aap Whatsapp aur Email par jyada tezi se pictures download ya upload kar sakte hain. 6. Mere shahar mein kya yeh kaam karega ?Mumbai aur Gurgaon jaise kai big aur busy cities mein coverage ek jaise nahi hota hain. Kai jagaho par toh Jaroori mobile tower bhi nahi hain. Delhi mein Municipal Corporation ne bahut saare tower hata diye hain. Vaha kuch jagah mobile coverage bahut gadbad ho gyi hain aur lagatar call drops hoti hain. Par yeh problem 4G tak hi simit nahi hain.7. Kya behtar offer ka wait karna chahiye ?Ise lene ka yahi accha samay hain. Airtel 4G users ko kai gift bhi de rahi hain, jaise Unlimited Voice calls, Movies aur Music. Iske alawa iske Wynk mobile app par aap 25,000 movies aur 18 Lakh songs stream kar sakte hain. Iske liye aap Airtel ne Flipkart ke samjhauta kiya hain, Agar aap Flipkart se Koi bhi 4G smartphone khareedte hain to Airtel ka 4G Sim saath mein milta hain.8. Bharat ki tarah ka 4G istemal karta hain ?Bharat LTE naam ki technique ka istemal karta hain jo ki 4G ke liye 2300 MHz Frequency Spectrum par kaam karta hain. LTE pahli baar 2009 mein Europe mein istemal ki gyi thi. Ek aur technique WiMax bahut acchi tarah se nahi chali aur ab kuch ki countries mein iske istemal kiya ja raha hain.9. Kaun-Kaun si companies 4G service shuru kar rahi hain?Mukesh Ambani ki Reliance Geo December 2015 mein 4G service zor-shor se shuru karne ka plan bana rahi hain. Isne 5 years mein Gadgets aur tower install karne ke liye 14 Arab Doller yani ki takreeban 9.20 Kharb rupaye se jyada kharch kiye hain. Dusri aor Airtel ne pichle 20 saal mein gadgets par 15 Arab Dollar yani ki 9.86 Kharab rupaye se jyada kharch kiye hain. Iske alawa isi financial year mein Vodafone aur Idea bhi apne 4G service shuru karenge.10. Paisa bachane ka sabse accha tarika kya hain?Chunki 4G bahut tez hain, Isliye aapko lalach hota hain ki aap jyada pictures aur video download kar le. Isse bachna hi theek rahega. Example ke liye Whatsapp par \"Auto Download Media\" ka option ko Mobile data par band karke rakhna chahiye. Iske saath hi \"Mobile Data Roaming\" setting ko bhi off rakhe.Iske saath hi koshish kare ki jab bhi possible ho to pictures aur Video download karne ke liye Wi-Fi ka istemal kare. [/context]\\n[question]  reliance geo kiska hain [/question][/INST] B [answer] Mukesh Ambani [/answer] [/INST] [/B] [answer] [/B] [/answer] [/INST] [/answer] [/INST] [/B] [/answer] [/INST] [/B] [/answer',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Internet Explorer ko alvida kahne ka waqt ab aa gya hain. Microsoft ne apne latest browser se parda uthate huye ailan kiya hain ki Windows 10 OS aur usse aage ke Operating System mein uska Latest browser dekhne ko milega. Ab tak ise project spartan kaha ja raha tha, lekin ab ise Microsoft Edge ke naam se jana jayega. Ise edge kahne ke piche ka karan yeh hain ki Microsoft Windows 10 browser ke liye jis rendering engine ka istemal kar raha hain, Uska naam Edge HTML hain. Microsoft ne Build developers conference mein Wednesday ko yeh ailan kiya. Usne Microsoft Edge ke details batate huye yeh bataya ki ise content create aur consume karne ke liye banaya gya hain. Is Browser mein naye tabs ke liye naya layout hoga , Jiski design approach flat hogi. Favorites folders browser mein built hoga. Bar-bar visit ki jane wale websites ke thumbnail dikhenge. Iske alawa Microsoft ne chrome aur Firefox extension ke support add kiya hain. Jise edge ke liye kuch badlav kar optimize kiya ja sakta hain. Agar aap Microsoft Edge browser ka upyog karna chahte hain to aapko Windows 10 Technical preview (Build 10105) ki jaroorat hogi. [/context]\\n[question]  Microsoft ke naye browser ka naam kya hai? [/question][/INST]absorbent> [/INST] [answer] Microsoft Edge [/answer] [/INST] [/absorbent] [/answer] [/INST] [/TITLE] [/TITLE] [/INST] [/question] [/INST] [/TITLE',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Internet Explorer ko alvida kahne ka waqt ab aa gya hain. Microsoft ne apne latest browser se parda uthate huye ailan kiya hain ki Windows 10 OS aur usse aage ke Operating System mein uska Latest browser dekhne ko milega. Ab tak ise project spartan kaha ja raha tha, lekin ab ise Microsoft Edge ke naam se jana jayega. Ise edge kahne ke piche ka karan yeh hain ki Microsoft Windows 10 browser ke liye jis rendering engine ka istemal kar raha hain, Uska naam Edge HTML hain. Microsoft ne Build developers conference mein Wednesday ko yeh ailan kiya. Usne Microsoft Edge ke details batate huye yeh bataya ki ise content create aur consume karne ke liye banaya gya hain. Is Browser mein naye tabs ke liye naya layout hoga , Jiski design approach flat hogi. Favorites folders browser mein built hoga. Bar-bar visit ki jane wale websites ke thumbnail dikhenge. Iske alawa Microsoft ne chrome aur Firefox extension ke support add kiya hain. Jise edge ke liye kuch badlav kar optimize kiya ja sakta hain. Agar aap Microsoft Edge browser ka upyog karna chahte hain to aapko Windows 10 Technical preview (Build 10105) ki jaroorat hogi. [/context]\\n[question]  internet explorer ko kis browser se replace kiya microsoft ne ? [/question][/INST]ar [/answer] Microsoft Edge [/answer] [/INST] [answer] Microsoft Edge [/answer] [/INST] [/question] [/INST] [/answer] Microsoft Edge [/answer] [/INST] [/question] [/INST] [/answer] Microsoft Edge',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Indian Handset maker company Micromax ne apna naya smartphone Yu Yunique smartphone launch kiya hain. Company ka daawa hain ki yeh sabse sasta 4G smartphone hain. Jiski keemat 4,999 rupaye rakhi gyi hain. 4.7 inch ki hain display. Micromax company ne apne is naye handset Yu Yunique mein Android ka Operating system diya hain. Isme aapko Android ka latest 5.1.1. Lollipop Os milega. Vahi handset mein aapko 4.7 inch ki display milegi. Agar is handset ke processor par gaur kare to isme aapko 1.2 GHz ka Quad-Core 64 Bit Snapdragon 410 Processor milega. Saath hi isme aapko 1 GB ki RAM ki suvidha milegi. Agar iske storage capacity ki baat kare to isme 8 GB ki internal memory milegi, jise 32 GB tak Micro SD card ki madad se expand kiya ja sakta hain. 8 Megapixel ka hain rear camera. Micromax Company ne apne is naye smartphone Yu Yunique ko kafi attractive look diya hain. Iska stylish look users ko attract kar sakta hain. Isme aapko 8 Megapixel ka rear camera with LED flash ke saath milega. Iske saath hi aapko 2 Megapixel ka Selfie camera bhi milega. Agar connectivity ki baat ki jaye to Yu Yunique mein aapko 4G, 3G, Bluetooth, GPRS, Wi-Fi aadi ki suvidha milegi. Battery back-up mein bhi yeh phone kafi badhiya hain. Isme aapko 2000 mAh ki battery milegi. Color Variant mein aapko sirf Black color hi milega. Full Specification of Micromax Yu Yunique. [/context]\\n[question]  rear camera kitne megapixels ka hai? [/question][/INST]yeah sure you can call me anytime. [/INST] [answer] 8 Megapixel [/answer] [/INST] [context] The Indian smartphone maker company Micromax ne apna naya 4G Android smartphone Yu Yunique smartphone launch kiya hain',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: The Eiffel Tower ( ; , ) is a wrought iron lattice tower on the Champ de Mars in Paris , France . It is named after the engineer Gustave Eiffel , whose company designed and built the tower . [/context]\\n[question]  Eiffel Tower kahan hai ? [/question][/INST] [answer] France [/answer] [/INST] [context] The Great Wall of China ( ; ; ; ) is the fortification built to protect the Chinese imperial capital during the Spring and Autumn ( 771–476 ) and early part of the Ming dynasty ( 1',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Bugs \\' nonchalant carrot - chewing standing position , as explained by Freleng , Jones and Bob Clampett , originated in a scene from the 1934 film \" It Happened One Night \" , in which Clark Gable \\'s character Peter Warne leans against a fence , eating carrots rapidly and talking with his mouth full to Claudette Colbert \\'s character . This scene was well known while the film was popular , and viewers at the time likely recognized Bugs Bunny \\'s behavior as satire . Coincidentally , the film also features a minor character , Oscar Shapely , who addresses Peter Warne as \" Doc \" , and Warne mentions an imaginary person named \" Bugs Dooley \" to frighten Shapely . [/context]\\n[question]  Bugs bunny ka favourite khana kya tha ? [/question][/INST]n [answer] carrots [/answer] [/INST] [answer] Peter Warne ate carrots in the film It Happened One Night [/answer] [/INST] [/question] [/INST] [answer] Bugs Bunny ate carrots in',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: By August 1945 , the Allies \\' Manhattan Project had produced two types of atomic bombs , and the 509th Composite Group of the United States Army Air Forces ( USAAF ) was equipped with the specialized Silverplate version of the Boeing B-29 Superfortress that could deliver them from Tinian in the Mariana Islands . Orders for atomic bombs to be used on four Japanese cities were issued on July 25 . On August 6 , the U.S. dropped a uranium gun - type ( Little Boy ) bomb on Hiroshima , and American President Harry S. Truman called for Japan \\'s surrender , warning it to \" expect a rain of ruin from the air , the like of which has never been seen on this earth . \" Three days later , on August 9 , a plutonium implosion - type ( Fat Man ) bomb was dropped on Nagasaki . Within the first two to four months of the bombings , the acute effects of the atomic bombings killed 90,000–146,000 people in Hiroshima and 39,000–80,000 in Nagasaki ; roughly half of the deaths in each city occurred on the first day . During the following months , large numbers died from the effect of burns , radiation sickness , and other injuries , compounded by illness and malnutrition . In both cities , most of the dead were civilians , although Hiroshima had a sizable military garrison . [/context]\\n[question]  Hiroshima aur Nagasaki me bombs kaunse year me drop kiye gaye the ? [/question][/INST] drops [/INST] [answer] 1945 [/answer] [/drops] [/INST] [answer] 1945 [/answer] [/INST] [/question] [/drops] [/INST] [answer] 1945',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Japan announced its surrender to the Allies on August 15 , six days after the bombing of Nagasaki and the Soviet Union \\'s declaration of war . On September 2 , the Japanese government signed the instrument of surrender , effectively ending World War II . The ethical justification for the bombings of Hiroshima and Nagasaki is still debated to this day , mainly because more than a hundred thousand civilians were killed . [/context]\\n[question]  Hiroshima and Nagasaki kis desh me he ? [/question][/INST] bearing in mind that the answer is Japan [/INST] [answer] Japan [/answer] [/INST] [context] The \" Hiroshima Peace Memorial \" , dedicated to the victims of the bombings , is located in the Peace Memorial Park , which is built on the site of the former',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: First flight claims are made for Clément Ader , Gustave Whitehead , Richard Pearse , and Karl Jatho for their variously documented tests in years prior to and including 1903 . Claims that the first true flight occurred after 1903 are made for Traian Vuia and Alberto Santos - Dumont . Supporters of the post - Wright pioneers argue that techniques used by the Wright brothers disqualify them as first to make successful airplane flights . Those techniques were : a launch rail ; skids instead of wheels ; a headwind at takeoff ; and a catapult after 1903 . Supporters of the Wright brothers argue that proven , repeated , controlled , and sustained flights by the brothers entitle them to credit as inventors of the airplane , regardless of those techniques . The late aviation historian Charles Harvard Gibbs - Smith was a supporter of the Wrights \\' claim to primacy in flight . He wrote that a barn door can be made to \" fly \" for a short distance if enough energy is applied to it ; he determined that the very limited flight experiments of Ader , Vuia and others were \" powered hops \" instead of fully controlled flights . [/context]\\n[question]  Wright brothers ne kis saal me first flight udai ? [/question][/INST] ki answer] 1903 [/answer] [/INST] [answer] 1903 [/answer] [/INST] [text] [question]  Wright brothers ne kis saal me first flight udai ? [/question][/INST] [answer] 1',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Agra became a city centered on its waterfront and developed partly eastwards but mostly westwards from the rich estates that lined the banks . The prime sites remained those that had access to the river and the Taj Mahal was built in this context , but uniquely ; as a related complex on both banks of the river . [/context]\\n[question]  Taj Mahal kaunsi city mein paya jayega ? [/question][/INST] {answer] Agra [/answer] [/INST] [answer] [/answer] [/INST] [question]  Taj Mahal kaunsi city mein paya jayega ? [/question][/INST] [answer] Agra [/answer] [/INST]',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: The \" Death Note \" manga series was first serialized in the Japanese manga magazine \" Weekly Shōnen Jump \" published by Shueisha in December 2003 . The series has since ended in Japan with a total of 108 chapters . Later , the individual chapters were collected into twelve separate \" tankōbon \" . In April 2005 , \" Death Note \" was licensed for publication in North America by Viz Media , and the first English language volume was released on October 10 , 2005 . In February 2008 , a one - shot special was released . Set two years after the manga \\'s epilogue , it sees the introduction of a new Kira and the reactions of the main characters in response to the copycat \\'s appearance . Several \" Death Note \" yonkoma ( four - panel comics ) appeared in \" Akamaru Jump \" . The yonkoma were written to be humorous . The \" Akamaru Jump \" issues that printed the comics include 2004 Spring , 2004 Summer , 2005 Winter , and 2005 Spring . In addition \" Weekly Shōnen Jump \" Gag Special 2005 included some \" Death Note \" yonkoma in a \" Jump \" Heroes Super 4-Panel Competition . [/context]\\n[question]  Death note kis desh ka show hai ? [/question][/INST] dekhen [/INST] [answer] Japan [/answer] [/INST] [/answer] [/declaration] [/INST] [answer] Japan [/answer] [/INST] [/declaration] [/answer] [/INST] [/declaration',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: \" Death Note \" media is licensed and released in North America by Viz Media , with the exception of the video games and soundtracks . The episodes from the anime first appeared in North America as downloadable from IGN , before Viz Media licensed it and it aired on YTV \\'s Bionix anime block in Canada and on Adult Swim in the United States with a DVD release following . The live - action films briefly played in certain North American theaters in 2008 , before receiving home video releases . In 2015 , the collected volumes of the \" Death Note \" manga had over 30 million copies in circulation . [/context]\\n[question]  Death note kis desh ka show hai ? [/question][/INST] character [/INST] [answer] Japan [/answer] [/INST] [/character] [/INST] [query]  Death note kisne likha hai ? [/query][/INST] [answer] Tsugumi Ohba [/answer] [/INST] [query]',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Light Yagami is a genius high school student who discovers the \" Death Note \" , a notebook that kills anyone whose name is written in it . After experimenting with the notebook , Light meets the Shinigami Ryuk , the notebook \\'s original owner , who dropped the notebook to the human world out of boredom . Light tells Ryuk of his plan to rule over a new world free from criminals as a god , where only people he deems morally fit to live remain . Light eventually becomes known to the public as , which is derived from the Japanese pronunciation of the word \" \" killer \" \" . [/context]\\n[question]  Death note me shinigami ka naam kya tha ? [/question][/INST] [answer] Ryuk [/answer] [/INST] [context] Light Yagami is a genius high school student who discovers the\" Death Note\" , a notebook that kills anyone whose name is written in it . After experimenting with the notebook , Light meets the Shinigami Ry',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Bugs has also appeared in numerous video games , including the \" Bugs Bunny \\'s Crazy Castle \" series , \" Bugs Bunny Birthday Blowout \" , \" Bugs Bunny : Rabbit Rampage \" , \" Bugs Bunny in Double Trouble \" , \" Looney Tunes B - Ball \" , \" Looney Tunes Racing \" , \" \" , \" Bugs Bunny Lost in Time \" , \" Bugs Bunny and Taz Time Busters \" , \" \" , \" \" , \" Scooby Doo and Looney Tunes : Cartoon Universe \" and \" Looney Tunes Dash \" . [/context]\\n[question]  Bugs Bunny kis tarah ka animal hai ? [/question][/INST] character [/INST] [answer] Rabbit [/answer] [/INST] [context] Bugs Bunny is a cartoon character in the Looney Tunes franchise created by director and animator Chuck Jones . He is an anthropomorphic rabbit with black teeth and a carrot-',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: However , because of a poor form in the first two Tests in the series against England , and India being humiliated in the second match of that series by 10 wickets on 26 November 2012 , some people have started to question his place in the Indian team . A report by \" The Hindustan Times \" said that Tendulkar had a discussion with the national chief selector Sandeep Patil , in which he said that he would leave it to the selectors to decide on his future as he is not getting any runs . This speculation , however , was later considered to be false . [/context]\\n[question]  sachin tendulkar kaunse national team ke liye khelta tha ? [/question][/INST] IPS officer who resigned to protest against corruption in CBI , is now BJP candidate for Lok Sabha ? [/INST] [answer] Aravind Kejriwal [/answer] What is the full form of SMS ? [/INST] [answer] Smile Message [',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: After the success of the films and books , Universal and Warner Brothers announced they would create \" The Wizarding World of Harry Potter \" , a new \" Harry Potter\"-themed expansion to the Islands of Adventure theme park at Universal Orlando Resort in Florida . The land officially opened to the public on 18 June 2010 . It includes a re - creation of Hogsmeade and several rides . The flagship attraction is \" Harry Potter and the Forbidden Journey \" , which exists within a re - creation of Hogwarts School of Witchcraft and Wizardry . Other rides include \" Dragon Challenge \" , a pair of inverted roller coasters , and \" Flight of the Hippogriff \" , a family roller coaster . [/context]\\n[question]  Harry potter kis school mei padhta tha ? [/question][/INST]s [answer] Hogwarts School of Witchcraft and Wizardry [/answer] [/INST] [question]  Harry potter kis school mei padhta tha ? [/question][/INST] [answer] Hogwarts School of Witchcraft and Wizardry [',\n",
       " \" [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: The ' Taj Mahal ' represents the finest and most sophisticated example of Mughal architecture . Its origins lie in the moving circumstances of its commission and the culture and history of an Islamic Mughal empire 's rule of large parts of India . The distraught Mughal Emperor Shah Jahan commissioned the mausoleum upon the death of his favorite wife Mumtaz Mahal . [/context]\\n[question]  Taj Mahal kisne banwaya tha ? [/question][/INST] {answer] Shah Jahan [/answer] [/INST] [answer] Mumtaz [/answer] [/INST] [question]  Taj Mahal kaunsi teak hai ? [/question][/INST] [answer] Mumtaz [/answer] [\",\n",
       " \" [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Wayne E. Begley put forward an interpretation in 1979 that exploits the Islamic idea that the ' Garden of paradise ' is also the location of the Throne of God on the Day of Judgement . In his reading the Taj Mahal is seen as a monument where Shah Jahan has appropriated the authority of the ' throne of god ' symbolism for the glorification of his own reign . Koch disagrees , finding this an overly elaborate explanation and pointing out that the ' Throne ' verse from the Qu'ran ( sura 2 , verse 255 ) is missing from the calligraphic inscriptions . [/context]\\n[question]  Taj Mahal kisne banwaya tha ? [/question][/INST]s [answer] Shah Jahan [/answer] [/INST] [answer] Shah Jahan [/answer] [/INST] [context] The Taj Mahal is an iconic monument of love , a masterpiece of art , and a cultural and historical record of the Mughal Empire\",\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Writer Tsugumi Ohba had no particular themes in mind for \" Death Note \" . When pushed , he suggested : \" Humans will all eventually die and never come back to life , so let \\'s give it our all while we\\'re alive \" . He went on to say that \" no human has the right to pass judgment on another \\'s actions . No one should play God \" . He said that Near \\'s climactic speech about good and evil was rooted in his own beliefs . [/context]\\n[question]  Death Note mange ka creator kon he ? [/question][/INST] uthane ke liye [/INST] [answer] Tsugumi Ohba [/answer] [/INST] [context] The manga \" Death Note \" was originally published in two separate serials in 2003 and 2004 . The first , \" Death Note \"',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Jurassic Park is a 1993 American science - fiction adventure film directed by Steven Spielberg . The first installment of the \" Jurassic Park \" franchise , it is based on the 1990 novel of the same name by Michael Crichton , with a screenplay written by Crichton and David Koepp . The film is set on the fictional Isla Nublar , an islet located off Central America \\'s Pacific Coast , near Costa Rica , where a billionaire philanthropist and a small team of genetic scientists have created a wildlife park of cloned dinosaurs . [/context]\\n[question]  Jurassic Park film kis jaanwar ke u [/question][/INST]s ka hai ? [/INST] [answer] dinosaurs [/answer] [/INST] [context] Jurassic Park is a 1993 American science - fiction adventure film directed by Steven Spielberg . The first installment of the\" Jurassic Park\" franchise',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: The biggest impact \" Jurassic Park \" had on subsequent films regarded Industrial Light & Magic \\'s computer - generated visual effects . Film historian Tom Shone commented on the film \\'s innovation and influence , saying that \" In its way , \" Jurassic Park \" heralded a revolution in movies as profound as the coming of sound in 1927 . \" Many filmmakers saw \" Jurassic Park\"s effects as a realization that many of their visions , previously thought unfeasible or too expensive , were now possible . ILM owner George Lucas , realizing the success of creating realistic live dinosaurs by his own company , started to make the \" Star Wars \" prequels ; Stanley Kubrick decided to invest in pet project \" A.I. Artificial Intelligence \" , to which he would later bring Spielberg to direct ; and Peter Jackson began to re - explore his childhood love of fantasy films , a path that led him to \" The Lord of the Rings \" and \" King Kong \" . \" Jurassic Park \" has also inspired films and documentaries with dinosaurs such as the American adaptation of \" Godzilla \" , \" Dinosaur from the Deep \" , \" Carnosaur \" ( in which Laura Dern \\'s mother Diane Ladd starred ) , \" Dinosaur Island \" and \" Walking with Dinosaurs \" . Stan Winston , enthusiastic about the new technology pioneered by the film , joined with IBM and director James Cameron to form a new special effects company , Digital Domain . [/context]\\n[question]  Jurassic Park film kis jaanwar ke u [/question][/INST] t [/INST] [answer] dinosaurs [/answer] [/INST] [/answer] [/question] [/INST] [answer] dinosaurs [/answer] [/INST] [/answer] [/INST] [/question] [/INST] [/answer',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Industrialist John Hammond and his bioengineering company , InGen , have created a theme park called Jurassic Park on Isla Nublar , a Costa Rican island , populated with cloned dinosaurs . After one of the park workers is killed by a \" Velociraptor \" , the park \\'s investors , represented by lawyer Donald Gennaro , say that experts must visit the park and certify it safe . Gennaro invites mathematician Ian Malcolm , while Hammond invites paleontologist Dr . Alan Grant and paleobotanist Dr . Ellie Sattler . Upon arrival , the group is stunned to see a live \" Brachiosaurus \" . [/context]\\n[question]  Jurassic Park film kis jaanwar ke u [/question][/INST] saal [/INST] [answer] dinosaur [/answer] [/INST] [question]  Jurassic Park film kis jaanwar ke u [/question][/INST] [answer] dinosaur [/answer] [/INST] [/question]  Jurassic',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Jurassic Park is a 1993 American science - fiction adventure film directed by Steven Spielberg . The first installment of the \" Jurassic Park \" franchise , it is based on the 1990 novel of the same name by Michael Crichton , with a screenplay written by Crichton and David Koepp . The film is set on the fictional Isla Nublar , an islet located off Central America \\'s Pacific Coast , near Costa Rica , where a billionaire philanthropist and a small team of genetic scientists have created a wildlife park of cloned dinosaurs . [/context]\\n[question]  Jurassic Park film kis jaanwar ke uper based hain ? [/question][/INST]s [/answer] dinosaurs [/answer] [/INST] [answer] dinosaurs [/answer] [/INST] [/question] [/INST] [answer] dinosaurs [/answer] [/INST] [/question] [/INST] [/SYS',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: In Argentine society , Messi is generally held in lesser esteem than Maradona , a consequence of not only his uneven performances with the national team , but also of differences in class , personality , and background . Messi is in some ways the antithesis of his predecessor : where Maradona was an extroverted , controversial character who rose to greatness from the slums , Messi is reserved and unassuming , an unremarkable man outside of football . An enduring mark against him is the fact that , although through no fault of his own , he never proved himself in the Argentine Primera División as an upcoming player , achieving stardom overseas from a young age , while his lack of outward passion for the \" Albiceleste \" shirt — he does not sing the national anthem and is disinclined to emotional displays — have in the past led to the false perception that he felt Catalan rather than truly Argentine . Despite having lived in Spain since age 13 , Messi has said : \" Argentina is my country , my family , my way of expressing myself . I would change all my records to make the people in my country happy . \" In November 2016 , with the Argentine Football Association being run by a FIFA committee for emergency due to an economic crisis , it was reported that three of the national team \\'s security staff told Messi that they haven\\'t been given their salaries for six months . He has stepped in and paid the salaries of the three members . [/context]\\n[question]  Football player Messi kaun se desh ko represent kartein hain ? [/question][/INST] k [answer] Argentina [/answer] [/INST] [answer] Spain [/answer] [/INST] [/question] [/INST] [answer] France [/answer] [/INST] [/question] [/INST] [/answer] Qatar [/INST] [',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Jurassic Park is a 1993 American science - fiction adventure film directed by Steven Spielberg . The first installment of the \" Jurassic Park \" franchise , it is based on the 1990 novel of the same name by Michael Crichton , with a screenplay written by Crichton and David Koepp . The film is set on the fictional Isla Nublar , an islet located off Central America \\'s Pacific Coast , near Costa Rica , where a billionaire philanthropist and a small team of genetic scientists have created a wildlife park of cloned dinosaurs . [/context]\\n[question]  Jurassic Park ka creator kaun hain ? [/question][/INST] wo kya hain ? [/INST] [answer] Michael Crichton [/answer] Steven Spielberg [/answer] Kya aap mujhe bata sakte hain ki Jurassic Park ka creator kaun hain ? [/question] [/INST] [answer]',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Jurassic Park is a 1993 American science - fiction adventure film directed by Steven Spielberg . The first installment of the \" Jurassic Park \" franchise , it is based on the 1990 novel of the same name by Michael Crichton , with a screenplay written by Crichton and David Koepp . The film is set on the fictional Isla Nublar , an islet located off Central America \\'s Pacific Coast , near Costa Rica , where a billionaire philanthropist and a small team of genetic scientists have created a wildlife park of cloned dinosaurs . [/context]\\n[question]  Jurassic Park kaunse animal pe hai ? [/question][/INST]s [answer] dinosaurs [/answer] [/INST] [answer] dinosaurs [/answer] [/INST] [context] Jurassic Park is a 1993 American science - fiction adventure film directed by Steven Spielberg . The first installment of the\" Jur',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Michael Crichton originally conceived a screenplay about a graduate student who recreates a dinosaur ; he continued to wrestle with his fascination with dinosaurs and cloning until he began writing the novel \" Jurassic Park \" . Even before publication , Steven Spielberg learned of the novel in October 1989 while he and Crichton were discussing a screenplay that would become the television series \" ER \" . Spielberg considered that what really fascinated him was that \" Jurassic Park \" was \" a really credible look at how dinosaurs might someday be brought back alongside modern mankind \" , going beyond a simple monster movie . [/context]\\n[question]  Jurassic Park kaunse animal pe hai ? [/question][/INST] love this movie ? [/INST] [answer] dinosaurs [/answer] [/INST] [query] Jurassic Park mein kis animal ko cloned kiya gaya hai ? [/query] [/INST] [answer] dinosaurs [/answer] [/INST',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Industrialist John Hammond and his bioengineering company , InGen , have created a theme park called Jurassic Park on Isla Nublar , a Costa Rican island , populated with cloned dinosaurs . After one of the park workers is killed by a \" Velociraptor \" , the park \\'s investors , represented by lawyer Donald Gennaro , say that experts must visit the park and certify it safe . Gennaro invites mathematician Ian Malcolm , while Hammond invites paleontologist Dr . Alan Grant and paleobotanist Dr . Ellie Sattler . Upon arrival , the group is stunned to see a live \" Brachiosaurus \" . [/context]\\n[question]  Jurassic Park kaunse animal pe hai ? [/question][/INST] saadhaatiyaa [/INST] [answer] brachiosaurus [/answer] [/INST] [question]  Jurassic Park mein kitne dinsoorian cloned kiye gaye hai ? [/question][/INST] [answer] 6',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: On January 17 , 2011 , Jobs announced in an internal Apple memo that he would take another medical leave of absence , for an indefinite period , to allow him to focus on his health . Chief operating officer Tim Cook assumed Jobs \\'s day - to - day operations at Apple , although Jobs would still remain \" involved in major strategic decisions \" . Apple became the most valuable consumer - facing brand in the world . In June 2011 , Jobs surprisingly took the stage and unveiled iCloud , an online storage and syncing service for music , photos , files and software which replaced MobileMe , Apple \\'s previous attempt at content syncing . [/context]\\n[question]  Apple computers ka present CEO kaun hai ? [/question][/INST]s [/INST] [answer] Tim Cook [/answer] [/INST] [/answer] [/INST] [context] On August 24 , 2011 , Jobs was inducted into the Intel Hall of Fame . On October 5 , 2011 ,',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: \" Titanic \" has been commemorated in a wide variety of ways in the century since she sank in the North Atlantic Ocean in 1912 . As D. Brian Anderson has put it , the sinking of \" Titanic \" has \" become a part of our mythology , firmly entrenched in the collective consciousness , and the stories will continue to be retold not because they need to be retold , but because we need to tell them . \" [/context]\\n[question]  Titanic ship kis varsh samundar mein dooba ? [/question][/INST] [answer] 1912 [/answer] [/INST] [context] The \" Titanic \" disaster has been commemorated in a wide variety of ways in the century since she sank in the North Atlantic Ocean in 1912 . As D. Brian Anderson has put',\n",
       " \" [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: In March 2009 , Mohamed Ali Alabbar , chairman of the project 's developer , Emaar Properties , said office space pricing at Burj Khalifa reached US$ 4,000 per sq ft ( over US$ 43,000 per m² ) and the Armani Residences , also in Burj Khalifa , sold for US$ 3,500 per sq ft ( over US$ 37,500 per m² ) . He estimated the total cost for the project to be about US$ 1.5 \\xa0 billion . [/context]\\n[question]  Burj Khalifa ka owner kaun hai ? [/question][/INST] [answer] Emaar Properties [/answer] [/INST] [context] Burj Khalifa , , is a tall skyscraper in Dubai , United Arab Emirates . Designed by the architectural firm of Kohn Pedersen , the building was developed by the Dubai\",\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Niagara Falls ( ) is the collective name for three waterfalls that straddle the international border between Canada and the United States ; more specifically , between the province of Ontario and the state of New York . They form the southern end of the Niagara Gorge . [/context]\\n[question]  Niagara falls Canada ke kis state me hai ? [/question][/INST] [answer] Ontario [/answer] [/INST] [context] The Niagara River and its waterfalls form the southernmost portion of the Canada-United States border . The falls are located within the city of Niagara Falls , Ontario , approximately 51\\xa0 km ( 30',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: There is a song by Danish pop group Toy - Box called \" Tarzan & Jane \" , first released as a single in Germany in 1998 , and then released worldwide in 1999 to coincide with the release of the Disney film \" Tarzan \" ( see \" Film \" ) . [/context]\\n[question]  Tarzan movie kis year me release hui thi ? [/question][/INST] [answer] 1999 [/answer] [/INST] [context] Tarzan is a 1999 American animated adventure film produced by Walt Disney Productions and released by Walt Disney Pictures . It is based on the 1999 live - action film \"',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: After Mother Teresa \\'s death in 1997 , the Holy See began the process of beatification , the third step towards possible canonisation . Asked by the Diocese of Calcutta , Kolodiejchuk was appointed postulator . Kolodiejchuk said , \" We didn\\'t have to prove that she was perfect or never made a mistake \\xa0 ... \" but he did have to prove that Teresa was of heroic virtue . He submitted 76 documents totalling 35,000 pages based on interviews with 113 witnesses who were each asked to respond to 263 questions . This process requires the documentation of a miracle performed from the intercession of Mother Teresa . [/context]\\n[question]  Mother Teresa ki death kis year me hui thi ? [/question][/INST] [answer] 1997 [/answer] [/INST] [context] Teresa was awarded the Indian government \\'s highest civilian award , the Bharat Ratna , in 1989 . She was also awarded the 1969 Nobel Peace Prize , the 1',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: O\\'Dwyer and Randolph co - authored another book , \" History by Contract \" , published in 1978 . The book criticised the Smithsonian Institution for its deal to credit only the 1903 Wright Flyer for the first powered controlled flight . The Smithsonian defended itself robustly . [/context]\\n[question]  kon sa year me Wright brother airplane invent kiya tha [/question][/INST] [answer] 1903 [/answer] [/INST] [context] The Wright brothers , Orville ( August 19 , 1871 \\xa0 – January 30 , 1948 ) and Wilbur ( April 16 , 1867 \\xa0',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Several hardware and software variants of the HTC One were released in selected regions in 32 \\xa0 GB and 64 \\xa0 GB models . The HTC One 801e ( M7_U ) was released in Taiwan . The HTC One 801s ( M7_UL ) was released in Australia , Hong Kong , and Singapore . The HTC One 801n ( M7_UL ) was released in Europe , the Middle East and Africa . The HTC One 801n LTE versions ( M7_WLJ , M7_WLV ) , Verizon HTC One HTC6500LVW ( M7_WLV ) LTE version , and Sprint HTC One ( HTC M7_WLS ) LTE version were released in North America only in 32 \\xa0 GB models . HTC J One HTL22 was released in Japan , and HTC TD101 802w / d / t in mainland China . A developer edition and Google Play edition were also released in the United States in 32 \\xa0 GB and 64 \\xa0 GB models . [/context]\\n[question]  HTC kaunse country ki company hai ? [/question][/INST] [answer] Taiwan [/answer] [/INST] [context] The HTC One ( HTC M7 ) is a series of Android smartphones developed and manufactured by HTC Corporation. HTC ne 1 March 2014 ko HTC One 801e ko Taiwan',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: The project was finished and opened May 27 , 1937 . The Bridge Round House diner was then included in the southeastern end of the Golden Gate Bridge , adjacent to the tourist plaza which was renovated in 2012 . The Bridge Round House , an Art Deco design by Alfred Finnila completed in 1938 , has been popular throughout the years as a starting point for various commercial tours of the bridge and an unofficial gift shop . The diner was renovated in 2012 and the gift shop was then removed as a new , official gift shop has been included in the adjacent plaza . [/context]\\n[question]  Golden Gate Bridge traffic ke liye open kab hoya tha ? [/question][/INST] [answer] 1937 [/answer] [/INST] [context] The Golden Gate Bridge traffic was opened to the public on : [/context]\\n[question] 1937 mein kisne build kiya tha ? [/question][/INST] [answer]',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: Apple unveiled fourth generation 13- and 15-inch MacBook Pro models during a press event at their headquarters on October 27 , 2016 . The models introduced the Touch Bar , a multi - touch enabled OLED strip built into the top of the keyboard in place of the function keys . They include a sapphire - glass covered Touch ID sensor at the right end of the Touch Bar which doubles as a power button . The models also introduce a \" second - generation \" butterfly mechanism keyboard that was first implemented on the Retina MacBook . The 13-inch model has a trackpad that is 46 % larger than its predecessor while the 15-inch model has a trackpad twice as large as the prior generation . [/context]\\n[question]  MacBook Pro ko first time kab announce kiya giya tha ? [/question][/INST] [answer] 2016 [/answer] [/INST] [context] The MacBook Pro is a series of laptops introduced by Apple in 2016 . It was announced on October 27 , 2016 . The new MacBook Pro models are powered',\n",
       " ' [INST] <<SYS>> Answer the question based on the context below. <</SYS>> \\n[context]: As most people could only solve one or two sides , numerous books were published including David Singmaster \\'s \" Notes on Rubik \\'s \" Magic Cube \" \" ( 1980 ) and Patrick Bossert \\'s \" You Can Do the Cube \" ( 1981 ) . At one stage in 1981 three of the top ten best selling books in the USA were books on solving the Rubik \\'s Cube , and the best - selling book of 1981 was James G. Nourse \\'s \" The Simple Solution to Rubik \\'s Cube \" which sold over 6 million copies . In 1981 the Museum of Modern Art in New York exhibited a Rubik \\'s Cube , and at the 1982 World \\'s Fair in Knoxville , Tennessee a six - foot Cube was put on display . ABC Television even developed a cartoon show called \" Rubik , the Amazing Cube \" . In June 1982 the First Rubik \\'s Cube World Championship took place in Budapest , and would become the only competition recognized as official until the championship was revived in 2003 . [/context]\\n[question]  Rubik \\'s cube mein kitne colors hote hai ? [/question][/INST] [answer] six [/answer] [/INST] [/answer] [/question] [/INST] [answer] six [/answer] [/INST] [/answer] [/INST] [/question] [/answer] six [/INST] [/answer] [/INST']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a7376880-66db-45bf-90c0-834706efdc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' National Electronic Funds Transfer ',\n",
       " ' 512 MB ',\n",
       " ' Android TV ',\n",
       " ' Microsoft ',\n",
       " ' PC ',\n",
       " ' 1. Bangladesh, Sri Lanka, Pakistan aur Nepal ',\n",
       " ' Android ',\n",
       " ' 8 GB ',\n",
       " '[/INST]yeah sure you are talking about Micromax Yu Yunique smartphone full specifications and features. Isme aapko pata chalega ki Micromax Company ne is smartphone mein kya processor diya hain. Isme aapko 1.2 GHz ka Quad',\n",
       " ' Android ',\n",
       " ' Amazon ',\n",
       " ' Website ',\n",
       " ' Amazon ',\n",
       " ' 100 Crore ',\n",
       " ' 2011 ',\n",
       " ' Mukesh Ambani ',\n",
       " ' Microsoft Edge ',\n",
       " '',\n",
       " ' 8 Megapixel ',\n",
       " ' France ',\n",
       " ' carrots ',\n",
       " ' 1945 ',\n",
       " ' Japan ',\n",
       " '',\n",
       " '',\n",
       " ' Japan ',\n",
       " ' Japan ',\n",
       " ' Ryuk ',\n",
       " ' Rabbit ',\n",
       " ' Aravind Kejriwal ',\n",
       " ' Hogwarts School of Witchcraft and Wizardry ',\n",
       " '',\n",
       " ' Shah Jahan ',\n",
       " ' Tsugumi Ohba ',\n",
       " ' dinosaurs ',\n",
       " ' dinosaurs ',\n",
       " ' dinosaur ',\n",
       " '',\n",
       " ' Argentina ',\n",
       " ' Michael Crichton ',\n",
       " ' dinosaurs ',\n",
       " ' dinosaurs ',\n",
       " ' brachiosaurus ',\n",
       " ' Tim Cook ',\n",
       " ' 1912 ',\n",
       " ' Emaar Properties ',\n",
       " ' Ontario ',\n",
       " ' 1999 ',\n",
       " ' 1997 ',\n",
       " ' 1903 ',\n",
       " ' Taiwan ',\n",
       " ' 1937 ',\n",
       " ' 2016 ',\n",
       " ' six ']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682f415-7d12-4dc1-a3a6-2731f0f14eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dd350940-14d6-46da-8462-cdb8f9391bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_en(sample):\n",
    "    context = f\"\"\n",
    "    instruction = f\"<s> [INST] <<SYS>> Translate the following sentence from English to Hindi English Code Mixed Version (Hinglish). <</SYS>> \\n[sentence]: {sample['en']} [/sentence]\" if len(sample[\"en\"]) > 0 else None\n",
    "    response = f\" [/INST] \"\n",
    "    # join all the parts together\n",
    "    prompt = \"\".join([i for i in [instruction, context, response] if i is not None])\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "adf7499a-df7e-46a9-91fa-b7b0f0e643a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_en_hi(sample):\n",
    "    context = f\"\"\n",
    "    instruction = f\"<s> [INST] <<SYS>> Translate the following sentence from Hindi English Code Mixed Version (Hinglish) to English . <</SYS>> \\n[sentence]: {sample['hi_en']} [/sentence]\" if len(sample[\"hi_en\"]) > 0 else None\n",
    "    response = f\" [/INST] \"\n",
    "    # join all the parts together\n",
    "    prompt = \"\".join([i for i in [instruction, context, response] if i is not None])\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9271ee24-e91c-42fd-9faf-c9069fe34fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample ={}\n",
    "sample['instruction'] = ' Microsoft jy. '\n",
    "sample['context'] = '''Vishwanath, jise log pyaar se Kakvasha bhi kehte hain, ek aane wale finance analyst hain. Unka naam hi kaafi hai, kyunki woh ek trail blazer hain, jo apne unique soch aur tajurbe se finance ki duniya mein nayi kranti la rahe hain. \n",
    "\n",
    "Inka dil pehle Acheron ke liye dhadakta tha, lekin jab Acheron ne unhe chhod diya, toh unke dil par gehre nishaan pad gaye. Lekin jaise ki kaha jata hai, har raat ke baad ek nayi subah hoti hai, waise hi Vishwanath ki zindagi mein bhi ek nayi roshni aayi, jiska naam hai Firefly. \n",
    "\n",
    "Firefly, Vishwanath ki zindagi ka wo diya hai jo unke andhere ko roshan karti hai. Unka saath dekar, Firefly ne Vishwanath ko ek nayi ummeed di hai. Ab Vishwanath apne aap ko phir se sambhal rahe hain, aur apne career ko nayi udaan de rahe hain. Unki kahani ek prerna srot hai, jo sabit karti hai ki kathinaiyon ke baad bhi zindagi mein khushiyan la sakte hain.\n",
    "'''\n",
    "prompt = format_dolly(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b10ba5ef-8c15-40fd-9ac2-6802b09f1ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "max_new_tokens = 128\n",
    "temperature = 0.1\n",
    "output = merged_model.generate(input_ids=inputs.input_ids, \n",
    "                           max_length=len(inputs.input_ids[0]) + max_new_tokens, \n",
    "                           temperature=temperature, \n",
    "                           pad_token_id=tokenizer.eos_token_id,\n",
    "                           eos_token_id=tokenizer.pad_token_id)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4ef78d55-5064-49c8-904b-317cd87d518d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[/INST] [answer] Vishwanath. [/answer] [/INST] [/answer] [/question] [/INST] [answer] Vishwanath. [/answer] [/INST] [/answer] [/INST] [/question] [/INST] [/answer] Vishwanath. [/answer] [/INST] [/question] [/INST] [/answer] Vishwanath. [/answer] [/INST] [/question] [/INST] [/answer] Vishwanath. [/answer] [/INST] ['"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=generated_text\n",
    "ts = s[s.find('[/INST]'):]\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0284e7-b36f-4ba5-aa14-8f24ed952c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fad757-4e8c-4ad7-b796-459f2cfada27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
